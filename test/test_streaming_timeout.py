#!/usr/bin/env python3
"""
æµå¼å“åº”è¶…æ—¶æµ‹è¯•
ç”¨äºè¯Šæ–­æµå¼å“åº”å¡ä½çš„é—®é¢˜
"""

import asyncio
import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

async def test_openai_streaming():
    """æµ‹è¯•OpenAIæµå¼å“åº”"""
    print("ğŸ§ª æµ‹è¯•OpenAIæµå¼å“åº”...")
    
    try:
        from core.chat_engine import ChatEngine
        from core.engine_manager import get_engine_manager
        from config.config import get_config
        
        # è·å–é…ç½®
        config = get_config()
        
        # è·å–å¼•æ“ç®¡ç†å™¨å¹¶åˆå§‹åŒ–å¼•æ“
        engine_manager = get_engine_manager()
        
        # æ ¹æ®é…ç½®åˆå§‹åŒ–å¼•æ“
        if config.CHAT_ENGINE == "mem0_proxy":
            from core.mem0_proxy import get_mem0_proxy
            mem0_engine = get_mem0_proxy()
            engine_manager.register_engine("mem0_proxy", mem0_engine)
            engine_manager.current_engine_name = "mem0_proxy"
            chat_engine = mem0_engine
        else:
            chat_engine_instance = ChatEngine()
            engine_manager.register_engine("chat_engine", chat_engine_instance)
            engine_manager.current_engine_name = "chat_engine"
            chat_engine = chat_engine_instance
        
        # å†æ¬¡è·å–èŠå¤©å¼•æ“
        chat_engine = engine_manager.get_current_engine()
        
        if not chat_engine:
            print("âŒ èŠå¤©å¼•æ“æœªåˆå§‹åŒ–")
            return
        
        print("âœ… èŠå¤©å¼•æ“å·²è·å–")
        
        # æ„å»ºæµ‹è¯•è¯·æ±‚
        request_params = {
            "model": "gpt-4.1",
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤"}
            ],
            "stream": True,
            "temperature": 0.7,
            "max_tokens": 100
        }
        
        print("ğŸ“¤ å¼€å§‹æµå¼è¯·æ±‚...")
        start_time = time.time()
        
        # è®¾ç½®è¶…æ—¶
        try:
            async with asyncio.timeout(30):  # 30ç§’è¶…æ—¶
                chunk_count = 0
                async for chunk in chat_engine.client.create_chat_stream(request_params):
                    chunk_count += 1
                    elapsed = time.time() - start_time
                    print(f"ğŸ“¥ [{elapsed:.1f}s] æ”¶åˆ°chunk #{chunk_count}")
                    
                    if chunk.choices and len(chunk.choices) > 0:
                        choice = chunk.choices[0]
                        if hasattr(choice.delta, 'content') and choice.delta.content:
                            print(f"ğŸ“ å†…å®¹: {choice.delta.content}")
                    
                    # é™åˆ¶æµ‹è¯•é•¿åº¦
                    if chunk_count > 10:
                        print("ğŸ›‘ æµ‹è¯•å®Œæˆï¼Œæ”¶åˆ°10ä¸ªchunk")
                        break
                
                print(f"âœ… æµå¼å“åº”å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f}ç§’")
                
        except asyncio.TimeoutError:
            print(f"â° æµå¼å“åº”è¶…æ—¶ ({time.time() - start_time:.2f}ç§’)")
        except Exception as e:
            print(f"âŒ æµå¼å“åº”é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def test_simple_streaming():
    """æµ‹è¯•ç®€å•çš„æµå¼å“åº”"""
    print("\nğŸ§ª æµ‹è¯•ç®€å•æµå¼å“åº”...")
    
    try:
        from core.chat_engine import ChatEngine
        from core.engine_manager import get_engine_manager
        from config.config import get_config
        
        # è·å–é…ç½®
        config = get_config()
        
        # è·å–å¼•æ“ç®¡ç†å™¨å¹¶åˆå§‹åŒ–å¼•æ“
        engine_manager = get_engine_manager()
        
        # æ ¹æ®é…ç½®åˆå§‹åŒ–å¼•æ“
        if config.CHAT_ENGINE == "mem0_proxy":
            from core.mem0_proxy import get_mem0_proxy
            mem0_engine = get_mem0_proxy()
            engine_manager.register_engine("mem0_proxy", mem0_engine)
            engine_manager.current_engine_name = "mem0_proxy"
            chat_engine = mem0_engine
        else:
            chat_engine_instance = ChatEngine()
            engine_manager.register_engine("chat_engine", chat_engine_instance)
            engine_manager.current_engine_name = "chat_engine"
            chat_engine = chat_engine_instance
        
        # å†æ¬¡è·å–èŠå¤©å¼•æ“
        chat_engine = engine_manager.get_current_engine()
        
        if not chat_engine:
            print("âŒ èŠå¤©å¼•æ“æœªåˆå§‹åŒ–")
            return
        
        # æ„å»ºæµ‹è¯•è¯·æ±‚
        request_params = {
            "model": "gpt-4.1",
            "messages": [
                {"role": "user", "content": "Hi"}
            ],
            "stream": True,
            "temperature": 0.7,
            "max_tokens": 50
        }
        
        print("ğŸ“¤ å¼€å§‹ç®€å•æµå¼è¯·æ±‚...")
        start_time = time.time()
        
        # è®¾ç½®è¶…æ—¶
        try:
            async with asyncio.timeout(20):  # 20ç§’è¶…æ—¶
                chunk_count = 0
                async for chunk in chat_engine.client.create_chat_stream(request_params):
                    chunk_count += 1
                    elapsed = time.time() - start_time
                    print(f"ğŸ“¥ [{elapsed:.1f}s] æ”¶åˆ°chunk #{chunk_count}")
                    
                    if chunk.choices and len(chunk.choices) > 0:
                        choice = chunk.choices[0]
                        if hasattr(choice.delta, 'content') and choice.delta.content:
                            print(f"ğŸ“ å†…å®¹: {choice.delta.content}")
                
                print(f"âœ… ç®€å•æµå¼å“åº”å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f}ç§’")
                
        except asyncio.TimeoutError:
            print(f"â° ç®€å•æµå¼å“åº”è¶…æ—¶ ({time.time() - start_time:.2f}ç§’)")
        except Exception as e:
            print(f"âŒ ç®€å•æµå¼å“åº”é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ ç®€å•æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµå¼å“åº”è¶…æ—¶æµ‹è¯•")
    print("=" * 50)
    
    await test_simple_streaming()
    await asyncio.sleep(2)
    await test_openai_streaming()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())
