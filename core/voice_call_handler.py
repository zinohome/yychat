"""
è¯­éŸ³é€šè¯å¤„ç†å™¨
ä¸“é—¨å¤„ç†å®æ—¶è¯­éŸ³é€šè¯åŠŸèƒ½ï¼Œä½¿ç”¨OpenAI Realtime API
"""

import asyncio
import base64
import time
import json
import os
import ssl
import websockets
from typing import Dict, Any, Optional
from utils.log import log
from core.websocket_manager import websocket_manager
from config.realtime_config import realtime_config
from adapters.personality_adapter import personality_adapter


class VoiceCallHandler:
    """è¯­éŸ³é€šè¯å¤„ç†å™¨ - ä¸“é—¨å¤„ç†å®æ—¶è¯­éŸ³é€šè¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯­éŸ³é€šè¯å¤„ç†å™¨"""
        # æ´»è·ƒçš„è¯­éŸ³é€šè¯è¿æ¥
        self.active_calls = {}  # client_id -> call_info
        # Realtime APIè¿æ¥
        self.realtime_connections = {}  # client_id -> websocket
        # æ¶ˆæ¯å¤„ç†ä»»åŠ¡
        self.message_tasks = {}  # client_id -> asyncio task
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šé¿å…é‡å¤å‘é€AIå›å¤ï¼ˆresponse.audio_transcript.done å’Œ response.done éƒ½ä¼šåŒ…å«ç›¸åŒæ–‡æœ¬ï¼‰
        self._assistant_text_sent = {}  # client_id -> {text: timestamp} è®°å½•å·²å‘é€çš„AIå›å¤æ–‡æœ¬
        # æ³¨æ„ï¼šOpenAI Realtime APIåœ¨åŒä¸€ä¸ªè¿æ¥ä¸­è‡ªåŠ¨ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡
        # ä¸éœ€è¦æ‰‹åŠ¨ç®¡ç†å¯¹è¯å†å²
        # æ³¨æ„ï¼šåªå¤„ç†å®Œæˆæ¶ˆæ¯ï¼ˆcompleted/doneï¼‰ï¼Œä¸å¤„ç†deltaå¢é‡æ¶ˆæ¯ï¼Œæ¯è½®å¯¹è¯åªè·å–ä¸¤æ¬¡å®Œæ•´æ–‡æœ¬ï¼ˆç”¨æˆ·ä¸€æ¬¡ï¼ŒAIä¸€æ¬¡ï¼‰
        
        log.info("è¯­éŸ³é€šè¯å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def start_voice_call(self, client_id: str) -> bool:
        """
        å¼€å§‹è¯­éŸ³é€šè¯
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            log.info(f"å¼€å§‹è¯­éŸ³é€šè¯: {client_id}")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ´»è·ƒé€šè¯
            if client_id in self.active_calls:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} å·²æœ‰æ´»è·ƒé€šè¯")
                return False
            
            # åˆ›å»ºRealtime APIè¿æ¥
            success = await self._create_realtime_connection(client_id)
            if not success:
                return False
            
            # è®°å½•é€šè¯ä¿¡æ¯
            self.active_calls[client_id] = {
                "start_time": time.time(),
                "status": "active",
                "message_count": 0
            }
            
            # å‘é€ç¡®è®¤æ¶ˆæ¯
            await websocket_manager.send_message(client_id, {
                "type": "voice_call_started",
                "message": "è¯­éŸ³é€šè¯å·²å¼€å§‹ï¼Œè¯·å¼€å§‹è¯´è¯",
                "timestamp": time.time(),
                "client_id": client_id
            })
            
            log.info(f"è¯­éŸ³é€šè¯å¯åŠ¨æˆåŠŸ: {client_id}")
            return True
            
        except Exception as e:
            log.error(f"å¯åŠ¨è¯­éŸ³é€šè¯å¤±è´¥: {client_id}, é”™è¯¯: {e}")
            await self._send_error(client_id, f"å¯åŠ¨è¯­éŸ³é€šè¯å¤±è´¥: {str(e)}")
            return False
    
    async def stop_voice_call(self, client_id: str) -> bool:
        """
        åœæ­¢è¯­éŸ³é€šè¯
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            log.info(f"ğŸ›‘ åœæ­¢è¯­éŸ³é€šè¯: {client_id}")
            
            # å¦‚æœæœ‰æ´»è·ƒçš„Realtimeè¿æ¥ï¼Œå…ˆå‘é€åœæ­¢å“åº”ä¿¡å·
            if client_id in self.realtime_connections:
                try:
                    websocket = self.realtime_connections[client_id]
                    # å‘é€åœæ­¢å“åº”ä¿¡å·åˆ°OpenAI
                    stop_message = {
                        "type": "response.cancel"
                    }
                    await websocket.send(json.dumps(stop_message))
                    log.info(f"ğŸ›‘ å·²å‘é€åœæ­¢å“åº”ä¿¡å·åˆ°OpenAI: {client_id}")
                except Exception as e:
                    log.warning(f"å‘é€åœæ­¢ä¿¡å·å¤±è´¥: {client_id}, é”™è¯¯: {e}")
            
            # æ¸…ç†è¿æ¥
            await self._cleanup_connection(client_id)
            
            # ç§»é™¤é€šè¯è®°å½•
            if client_id in self.active_calls:
                del self.active_calls[client_id]
            
            # OpenAI Realtime APIåœ¨è¿æ¥å…³é—­æ—¶è‡ªåŠ¨æ¸…ç†ä¸Šä¸‹æ–‡
            
            # å‘é€åœæ­¢æ’­æ”¾æŒ‡ä»¤åˆ°å‰ç«¯
            await websocket_manager.send_message(client_id, {
                "type": "stop_playback",
                "message": "åœæ­¢æ‰€æœ‰è¯­éŸ³æ’­æ”¾",
                "timestamp": time.time(),
                "client_id": client_id
            })
            
            # å‘é€ç¡®è®¤æ¶ˆæ¯
            await websocket_manager.send_message(client_id, {
                "type": "voice_call_stopped",
                "message": "è¯­éŸ³é€šè¯å·²åœæ­¢",
                "timestamp": time.time(),
                "client_id": client_id
            })
            
            log.info(f"âœ… è¯­éŸ³é€šè¯åœæ­¢æˆåŠŸ: {client_id}")
            return True
            
        except Exception as e:
            log.error(f"åœæ­¢è¯­éŸ³é€šè¯å¤±è´¥: {client_id}, é”™è¯¯: {e}")
            await self._send_error(client_id, f"åœæ­¢è¯­éŸ³é€šè¯å¤±è´¥: {str(e)}")
            return False
    
    async def handle_audio_stream(self, client_id: str, audio_data: str = None, audio_base64: str = None) -> bool:
        """
        å¤„ç†éŸ³é¢‘æµæ•°æ® - åŸºäºOpenAI Voice Agentsæœ€ä½³å®è·µ
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            audio_data: base64ç¼–ç çš„éŸ³é¢‘æ•°æ®ï¼ˆæ—§æ ¼å¼ï¼‰
            audio_base64: base64ç¼–ç çš„éŸ³é¢‘æ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒé€šè¯
            if client_id not in self.active_calls:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰æ´»è·ƒçš„è¯­éŸ³é€šè¯")
                return False
            
            # æ£€æŸ¥Realtimeè¿æ¥
            if client_id not in self.realtime_connections:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰Realtime APIè¿æ¥")
                return False
            
            # è·å–éŸ³é¢‘æ•°æ®ï¼ˆå…¼å®¹ä¸¤ç§æ ¼å¼ï¼‰
            actual_audio_data = audio_base64 if audio_base64 else audio_data
            if not actual_audio_data:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰æä¾›éŸ³é¢‘æ•°æ®")
                return False
            
            # åŸºäºæ–‡æ¡£çš„ä¼˜åŒ–ï¼šå®æ—¶éŸ³é¢‘æµå¤„ç†
            websocket = self.realtime_connections[client_id]
            
            # å‘é€éŸ³é¢‘æ•°æ®åˆ°Realtime API - ä½¿ç”¨æ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼
            audio_message = {
                "type": "input_audio_buffer.append",
                "audio": actual_audio_data
            }
            
            await websocket.send(json.dumps(audio_message))
            
            # æ›´æ–°é€šè¯ç»Ÿè®¡
            self.active_calls[client_id]["message_count"] += 1
            self.active_calls[client_id]["last_audio_time"] = time.time()
            
            # æ£€æŸ¥éŸ³é¢‘æ•°æ®è´¨é‡
            audio_size = len(actual_audio_data)
            # è®¡ç®—éŸ³é¢‘æ—¶é—´é•¿åº¦ï¼šPCM16æ ¼å¼ï¼Œ16kHzé‡‡æ ·ç‡ï¼Œ2å­—èŠ‚/æ ·æœ¬
            audio_duration_ms = (audio_size / 2) / 16000 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            if audio_size < 4000:  # æé«˜æœ€å°éŸ³é¢‘æ•°æ®è¦æ±‚
                log.warning(f"âš ï¸ éŸ³é¢‘æ•°æ®å¤ªå°: {client_id}, å¤§å°: {audio_size}å­—èŠ‚, æ—¶é•¿: {audio_duration_ms:.1f}ms, å»ºè®®è‡³å°‘4000å­—èŠ‚")
            elif audio_size > 50000:
                log.warning(f"âš ï¸ éŸ³é¢‘æ•°æ®å¤ªå¤§: {client_id}, å¤§å°: {audio_size}å­—èŠ‚, æ—¶é•¿: {audio_duration_ms:.1f}ms")
            elif audio_duration_ms < 100:
                log.warning(f"âš ï¸ éŸ³é¢‘æ—¶é•¿ä¸è¶³: {client_id}, å¤§å°: {audio_size}å­—èŠ‚, æ—¶é•¿: {audio_duration_ms:.1f}ms, éœ€è¦è‡³å°‘100ms")
            
            # æ¯100ä¸ªéŸ³é¢‘åŒ…è®°å½•ä¸€æ¬¡è´¨é‡ä¿¡æ¯
            if self.active_calls[client_id]["message_count"] % 100 == 0:
                log.info(f"ğŸµ éŸ³é¢‘è´¨é‡æ£€æŸ¥: {client_id}, å¤§å°: {audio_size}å­—èŠ‚, æ—¶é•¿: {audio_duration_ms:.1f}ms, è®¡æ•°: {self.active_calls[client_id]['message_count']}")
            
            # åŸºäºå®˜æ–¹æ–‡æ¡£ï¼šè®©æœåŠ¡å™¨ç«¯VADè‡ªåŠ¨å¤„ç†è¯­éŸ³æ£€æµ‹
            # ä¸ä¸»åŠ¨è§¦å‘response.createï¼Œè®©turn_detectionè‡ªåŠ¨å¤„ç†
            
            log.debug(f"å‘é€éŸ³é¢‘æ•°æ®åˆ°Realtime API: {client_id}, æ•°æ®å¤§å°: {len(actual_audio_data)}")
            #log.debug(f"éŸ³é¢‘æ¶ˆæ¯å†…å®¹: {audio_message}")
            return True
            
        except Exception as e:
            log.error(f"å¤„ç†éŸ³é¢‘æµå¤±è´¥: {client_id}, é”™è¯¯: {e}")
            await self._send_error(client_id, f"å¤„ç†éŸ³é¢‘æµå¤±è´¥: {str(e)}")
            return False
    
    async def handle_audio_complete(self, client_id: str) -> bool:
        """
        å¤„ç†éŸ³é¢‘å®Œæˆä¿¡å· - ç”¨æˆ·åœæ­¢è¯´è¯
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if client_id not in self.active_calls:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰æ´»è·ƒçš„é€šè¯")
                return False
            
            if client_id not in self.realtime_connections:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰Realtime APIè¿æ¥")
                return False
            
            websocket = self.realtime_connections[client_id]
            
            # å‘é€éŸ³é¢‘å®Œæˆä¿¡å·åˆ°Realtime API
            complete_message = {
                "type": "input_audio_buffer.commit"
            }
            
            await websocket.send(json.dumps(complete_message))
            log.info(f"ğŸ¤ ç”¨æˆ·åœæ­¢è¯´è¯ï¼Œæäº¤éŸ³é¢‘: {client_id}")
            
            # OpenAI Realtime APIä¼šè‡ªåŠ¨ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ— éœ€æ‰‹åŠ¨è®°å½•
            
            # OpenAI Realtime APIä¼šè‡ªåŠ¨å¤„ç†éŸ³é¢‘å¹¶åˆ›å»ºå“åº”
            # æ— éœ€æ‰‹åŠ¨è§¦å‘ response.createï¼Œé¿å…é‡å¤å“åº”
            log.debug(f"éŸ³é¢‘å·²æäº¤ï¼Œç­‰å¾…OpenAIè‡ªåŠ¨å“åº”: {client_id}")
            
            return True
            
        except Exception as e:
            log.error(f"å¤„ç†éŸ³é¢‘å®Œæˆå¤±è´¥: {client_id}, é”™è¯¯: {e}")
            await self._send_error(client_id, f"å¤„ç†éŸ³é¢‘å®Œæˆå¤±è´¥: {str(e)}")
            return False
    
    async def handle_interrupt(self, client_id: str) -> bool:
        """
        å¤„ç†æ‰“æ–­ä¿¡å· - ç”¨æˆ·å¼€å§‹è¯´è¯æ‰“æ–­AIå›å¤
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if client_id not in self.active_calls:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰æ´»è·ƒçš„é€šè¯")
                return False
            
            if client_id not in self.realtime_connections:
                log.warning(f"å®¢æˆ·ç«¯ {client_id} æ²¡æœ‰Realtime APIè¿æ¥")
                return False
            
            websocket = self.realtime_connections[client_id]
            
            # å‘é€å–æ¶ˆä¿¡å·åˆ°Realtime APIï¼Œåœæ­¢å½“å‰å“åº”
            cancel_message = {
                "type": "response.cancel"
            }
            
            await websocket.send(json.dumps(cancel_message))
            log.info(f"ğŸ›‘ ç”¨æˆ·æ‰“æ–­AIå›å¤ï¼Œåœæ­¢å½“å‰å“åº”: {client_id}")
            
            # å‘é€ç¡®è®¤æ¶ˆæ¯åˆ°å‰ç«¯
            await websocket_manager.send_message(client_id, {
                "type": "interrupt_confirmed",
                "message": "å·²åœæ­¢å½“å‰å›å¤ï¼Œç­‰å¾…æ–°çš„è¾“å…¥",
                "timestamp": time.time()
            })
            
            return True
            
        except Exception as e:
            log.error(f"å¤„ç†æ‰“æ–­ä¿¡å·å¤±è´¥: {client_id}, é”™è¯¯: {e}")
            await self._send_error(client_id, f"å¤„ç†æ‰“æ–­ä¿¡å·å¤±è´¥: {str(e)}")
            return False
    
    async def _create_realtime_connection(self, client_id: str) -> bool:
        """
        åˆ›å»ºRealtime APIè¿æ¥ - åŸºäºOpenAI Voice Agentsæœ€ä½³å®è·µ
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # è·å–OpenAI APIå¯†é’¥ - ä½¿ç”¨realtime_configä¸­çš„é…ç½®
            api_key = realtime_config.OPENAI_API_KEY
            if not api_key:
                raise Exception("OpenAI API key not configured")
            
            # æ„å»ºè¿æ¥URLå’Œå¤´éƒ¨
            url = realtime_config.get_realtime_url()
            headers = {
                "Authorization": f"Bearer {api_key}",
                "OpenAI-Beta": "realtime=v1",
                "User-Agent": "YYChat-VoiceAgent/1.0"
            }
            
            # å»ºç«‹WebSocketè¿æ¥ - ä¿®å¤SSLå’Œå‚æ•°é—®é¢˜
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            websocket = await websockets.connect(
                url, 
                additional_headers=headers,
                ping_interval=20,  # ä¿æŒè¿æ¥æ´»è·ƒ
                ping_timeout=10,   # å¿«é€Ÿæ£€æµ‹æ–­çº¿
                close_timeout=5,    # å¿«é€Ÿå…³é—­
                ssl=ssl_context  # ä½¿ç”¨è‡ªå®šä¹‰SSLä¸Šä¸‹æ–‡ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰
            )
            self.realtime_connections[client_id] = websocket
            
            # å¯åŠ¨æ¶ˆæ¯å¤„ç†ä»»åŠ¡
            task = asyncio.create_task(self._handle_realtime_messages(client_id, websocket))
            self.message_tasks[client_id] = task
            
            # è¿æ¥å»ºç«‹åï¼Œç«‹å³å‘é€session.updateé…ç½®
            await self._configure_session(client_id, websocket)
            
            log.info(f"Realtime APIè¿æ¥å·²å»ºç«‹: {client_id}")
            return True
            
        except Exception as e:
            log.error(f"åˆ›å»ºRealtime APIè¿æ¥å¤±è´¥: {client_id}, é”™è¯¯: {e}")
            # å‘é€é”™è¯¯æ¶ˆæ¯åˆ°å‰ç«¯
            await self._send_error(client_id, f"è¯­éŸ³é€šè¯è¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    async def _configure_session(self, client_id: str, websocket):
        """
        é…ç½®Realtime APIä¼šè¯ - åŠ¨æ€ä½¿ç”¨å½“å‰personality
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            websocket: WebSocketè¿æ¥
        """
        try:
            # è·å–å½“å‰personalityé…ç½®
            personality_config = self._get_current_personality_config()
            
            # åŸºäºpersonalityé…ç½®ä¼šè¯
            instructions = personality_config["instructions"]
            log.info(f"ğŸ¯ å‘é€ç»™OpenAIçš„instructions: {instructions[:200]}...")
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œsession.updateçš„æ­£ç¡®æ ¼å¼
            # æ³¨æ„ï¼šOpenAI Realtime APIä¸æ”¯æŒsession.messageså‚æ•°
            session_config = {
                "type": "session.update",
                "session": {
                    "modalities": ["audio", "text"],
                    "instructions": instructions,
                    "voice": "shimmer",
                    "input_audio_format": "pcm16",
                    "output_audio_format": "pcm16",
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.2,  # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼ï¼Œé€‚åº”ä½éŸ³é‡ç¯å¢ƒ
                        "prefix_padding_ms": 600,  # å¢åŠ å‰ç¼€å¡«å……ï¼Œæ•è·æ›´å¤šè¯­éŸ³
                        "silence_duration_ms": 400,  # å¢åŠ é™éŸ³æ—¶é—´ï¼Œç¡®ä¿å®Œæ•´è¯­éŸ³
                        "idle_timeout_ms": 30000,  # æ·»åŠ ç©ºé—²è¶…æ—¶
                        "create_response": True,  # å…è®¸åˆ›å»ºå“åº”
                        "interrupt_response": True  # å…è®¸æ‰“æ–­å“åº”
                    },
                    "input_audio_transcription": {
                        "model": "whisper-1"  # å¯ç”¨è½¬å½•åŠŸèƒ½
                    },
                    "tools": [],
                    "tool_choice": "none",
                    "temperature": 0.8,
                    "max_response_output_tokens": 4096
                }
            }
            
            await websocket.send(json.dumps(session_config))
            log.debug(f"ä¼šè¯é…ç½®å·²å‘é€: {client_id}")
            log.info(f"ğŸ“¤ å‘é€çš„sessioné…ç½®: {json.dumps(session_config, ensure_ascii=False)[:300]}...")
            
        except Exception as e:
            log.error(f"é…ç½®ä¼šè¯å¤±è´¥: {client_id}, é”™è¯¯: {e}")
            raise
    
    def _get_current_personality_config(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰personalityé…ç½®
        
        Returns:
            Dict[str, Any]: personalityé…ç½®
        """
        try:
            # å°è¯•è·å–å½“å‰ç”¨æˆ·é€‰æ‹©çš„personality
            # è¿™é‡Œå¯ä»¥ä»sessionæˆ–ç”¨æˆ·é…ç½®ä¸­è·å–
            # æš‚æ—¶ä½¿ç”¨health_assistantä½œä¸ºé»˜è®¤å€¼
            personality_id = "health_assistant"
            
            # é€šè¿‡personality_adapterè·å–é…ç½®
            personality_config = personality_adapter.get_personality_for_realtime(personality_id)
            
            if not personality_config:
                log.warning("æ— æ³•è·å–personalityé…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return self._get_default_personality_config()
            
            log.info(f"æˆåŠŸè·å–personalityé…ç½®: {personality_id}")
            instructions = personality_config.get('instructions', '')
            log.debug(f"Personality instructions: {instructions[:200]}...")
            log.info(f"ğŸ¯ å½“å‰ä½¿ç”¨çš„instructions: {instructions[:100]}...")
            return personality_config
            
        except Exception as e:
            log.error(f"è·å–personalityé…ç½®å¤±è´¥: {e}")
            return self._get_default_personality_config()
    
    def _get_default_personality_config(self) -> Dict[str, Any]:
        """
        è·å–é»˜è®¤personalityé…ç½®
        
        Returns:
            Dict[str, Any]: é»˜è®¤é…ç½®
        """
        return {
            "instructions": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥è¿›è¡Œå®æ—¶è¯­éŸ³å¯¹è¯ã€‚è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¿æŒç®€æ´è‡ªç„¶ã€‚",
            "voice": "shimmer",
            "allowed_tools": []
        }
    
    async def _handle_realtime_messages(self, client_id: str, websocket):
        """
        å¤„ç†Realtime APIè¿”å›çš„æ¶ˆæ¯
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            websocket: WebSocketè¿æ¥
        """
        try:
            async for message in websocket:
                try:
                    data = json.loads(message)
                    await self._process_realtime_response(client_id, data, websocket)
                except json.JSONDecodeError as e:
                    log.error(f"è§£æRealtime APIæ¶ˆæ¯å¤±è´¥: {e}")
                except Exception as e:
                    log.error(f"å¤„ç†Realtime APIæ¶ˆæ¯å¤±è´¥: {e}")
                    
        except websockets.exceptions.ConnectionClosed:
            log.info(f"Realtime APIè¿æ¥å·²å…³é—­: {client_id}")
        except Exception as e:
            log.error(f"Realtime APIæ¶ˆæ¯å¤„ç†å¼‚å¸¸: {client_id}, é”™è¯¯: {e}")
        finally:
            # æ¸…ç†è¿æ¥
            await self._cleanup_connection(client_id)
    
    async def _process_realtime_response(self, client_id: str, data: dict, websocket):
        """
        å¤„ç†Realtime APIå“åº”
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            data: å“åº”æ•°æ®
            websocket: WebSocketè¿æ¥
        """
        try:
            message_type = data.get("type")
            
            # å¤„ç†æ—¥å¿—æ˜¾ç¤ºï¼Œæˆªæ–­è¿‡é•¿çš„deltaå†…å®¹
            log_data = data.copy()
            if "delta" in log_data and isinstance(log_data["delta"], str):
                delta_content = log_data["delta"]
                if len(delta_content) > 15:
                    log_data["delta"] = delta_content[:15] + "..."
            
            log.debug(f"æ”¶åˆ°Realtime APIæ¶ˆæ¯: {client_id}, ç±»å‹: {message_type}, æ•°æ®: {log_data}")
            
            # ğŸ” è°ƒè¯•ï¼šè®°å½•æ‰€æœ‰æ¶ˆæ¯ç±»å‹ï¼Œç‰¹åˆ«æ˜¯è½¬å½•ç›¸å…³çš„
            if "transcription" in message_type.lower() or "input_audio" in message_type.lower():
                log.info(f"ğŸ” [è°ƒè¯•] æ”¶åˆ°å¯èƒ½ä¸è½¬å½•ç›¸å…³çš„æ¶ˆæ¯: {client_id}, ç±»å‹: {message_type}")
            
            if message_type == "response.audio.delta":
                # å¤„ç†éŸ³é¢‘è¾“å‡º - è¯­éŸ³é€šè¯çš„æ ¸å¿ƒåŠŸèƒ½
                audio_data = data.get("delta", "")
                if audio_data:
                    log.info(f"ğŸµ æ”¶åˆ°AIéŸ³é¢‘æ•°æ®: {client_id}, æ•°æ®å¤§å°: {len(audio_data)}")
                    await websocket_manager.send_message(client_id, {
                        "type": "audio_stream",
                        "audio": audio_data,
                        "message_id": f"voice_call_{client_id}_{int(time.time())}",
                        "session_id": f"voice_call_{client_id}",
                        "timestamp": time.time()
                    })
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç§»é™¤æ‰€æœ‰deltaå¢é‡å¤„ç†ï¼Œåªå¤„ç†å®Œæˆæ¶ˆæ¯
            # ä¸å¤„ç† response.text.deltaã€response.audio_transcript.delta ç­‰å¢é‡æ¶ˆæ¯
            # åªå¤„ç†å®Œæˆæ¶ˆæ¯ï¼ˆcompleted/doneï¼‰ï¼Œæ¯è½®å¯¹è¯åªè·å–ä¸¤æ¬¡å®Œæ•´æ–‡æœ¬ï¼ˆç”¨æˆ·ä¸€æ¬¡ï¼ŒAIä¸€æ¬¡ï¼‰
            
            elif message_type == "input_audio_buffer.speech_started":
                # æœåŠ¡å™¨ç«¯VADæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                log.info(f"ğŸ¤ æœåŠ¡å™¨ç«¯VADæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹: {client_id}")
                
            elif message_type == "input_audio_buffer.speech_stopped":
                # æœåŠ¡å™¨ç«¯VADæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
                log.info(f"ğŸ¤ æœåŠ¡å™¨ç«¯VADæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ: {client_id}")
            
            elif message_type == "conversation.item.input_audio_transcription.completed":
                # ğŸ”§ ç”¨æˆ·è½¬å½•å®Œæˆ - OpenAI Realtime APIçš„å®Œæˆæ¶ˆæ¯ï¼ˆæ¯è½®å¯¹è¯åªè·å–ä¸€æ¬¡å®Œæ•´æ–‡æœ¬ï¼‰
                # æ ¹æ®OpenAIæ–‡æ¡£ï¼šhttps://platform.openai.com/docs/guides/realtime-conversations
                # è¿™æ˜¯ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬çš„å®Œæˆæ¶ˆæ¯ï¼ŒåŒ…å«å®Œæ•´çš„transcriptå­—æ®µ
                transcribed_text = data.get("transcript", "")  # OpenAIæ–‡æ¡£ï¼šå­—æ®µåæ˜¯ transcript
                log.info(f"ğŸ“ [ç”¨æˆ·è½¬å½•å®Œæˆ] æ”¶åˆ°conversation.item.input_audio_transcription.completed: {client_id}, æ–‡æœ¬é•¿åº¦: {len(transcribed_text) if transcribed_text else 0}")
                
                if transcribed_text and realtime_config.VOICE_CALL_SEND_TRANSCRIPTION:
                    current_time = time.time()
                    log.info(f"ğŸ“ [ç”¨æˆ·è½¬å½•] å®Œæ•´æ–‡æœ¬: {client_id}, æ–‡æœ¬: {transcribed_text[:50]}...")
                    await websocket_manager.send_message(client_id, {
                        "type": "transcription_result",
                        "text": transcribed_text,  # ç”¨æˆ·è½¬å½•æ–‡æœ¬
                        "timestamp": current_time,
                        "client_id": client_id,
                        "scenario": "voice_call",
                        "message_id": f"voice-call-user-{client_id}-{int(current_time * 1000)}",
                        "role": "user"  # æ˜ç¡®æ ‡è¯†ä¸ºç”¨æˆ·æ¶ˆæ¯
                    })
                    log.info(f"âœ… [ç”¨æˆ·è½¬å½•] å·²å‘é€å®Œæ•´æ–‡æœ¬åˆ°å‰ç«¯: {client_id}, æ–‡æœ¬é•¿åº¦: {len(transcribed_text)}")
                else:
                    log.warning(f"âš ï¸ [ç”¨æˆ·è½¬å½•] æœªå‘é€: æ–‡æœ¬ä¸ºç©º={not transcribed_text}, é…ç½®ç¦ç”¨={not realtime_config.VOICE_CALL_SEND_TRANSCRIPTION}")
            
            elif message_type == "input_audio_buffer.transcription.completed":
                # å¤‡ç”¨ï¼šæ—§ç‰ˆAPIçš„æ¶ˆæ¯ç±»å‹ï¼ˆå…¼å®¹æ€§ï¼‰
                transcribed_text = data.get("text", "")  # æ—§ç‰ˆAPIå¯èƒ½ä½¿ç”¨textå­—æ®µ
                log.info(f"ğŸ“ [ç”¨æˆ·è½¬å½•å®Œæˆ-æ—§ç‰ˆ] æ”¶åˆ°input_audio_buffer.transcription.completed: {client_id}, æ–‡æœ¬é•¿åº¦: {len(transcribed_text) if transcribed_text else 0}")
                
                if transcribed_text and realtime_config.VOICE_CALL_SEND_TRANSCRIPTION:
                    current_time = time.time()
                    log.info(f"ğŸ“ [ç”¨æˆ·è½¬å½•-æ—§ç‰ˆ] å®Œæ•´æ–‡æœ¬: {client_id}, æ–‡æœ¬: {transcribed_text[:50]}...")
                    await websocket_manager.send_message(client_id, {
                        "type": "transcription_result",
                        "text": transcribed_text,
                        "timestamp": current_time,
                        "client_id": client_id,
                        "scenario": "voice_call",
                        "message_id": f"voice-call-user-{client_id}-{int(current_time * 1000)}",
                        "role": "user"  # æ˜ç¡®æ ‡è¯†ä¸ºç”¨æˆ·æ¶ˆæ¯
                    })
                    log.info(f"âœ… [ç”¨æˆ·è½¬å½•-æ—§ç‰ˆ] å·²å‘é€å®Œæ•´æ–‡æœ¬åˆ°å‰ç«¯: {client_id}, æ–‡æœ¬é•¿åº¦: {len(transcribed_text)}")
            
            elif message_type == "input_audio_buffer.transcription.failed":
                # è½¬å½•å¤±è´¥
                error = data.get("error", {})
                error_message = error.get("message", "Unknown error")
                log.warning(f"âš ï¸ ç”¨æˆ·è½¬å½•å¤±è´¥: {client_id}, é”™è¯¯: {error_message}")
                
            elif message_type == "response.audio_transcript.done":
                # ğŸ”§ AIéŸ³é¢‘è½¬å½•å®Œæˆ - OpenAI Realtime APIçš„å®Œæˆæ¶ˆæ¯ï¼ˆæ¯è½®å¯¹è¯åªè·å–ä¸€æ¬¡å®Œæ•´æ–‡æœ¬ï¼‰
                # æ ¹æ®OpenAIæ–‡æ¡£ï¼šè¿™æ˜¯AIå›å¤éŸ³é¢‘è½¬æ–‡æœ¬çš„å®Œæˆæ¶ˆæ¯ï¼ŒåŒ…å«å®Œæ•´çš„transcriptå­—æ®µ
                assistant_text = data.get("transcript", "")  # OpenAIæ–‡æ¡£ï¼šå­—æ®µåæ˜¯ transcript
                log.info(f"ğŸ” [AIè½¬å½•å®Œæˆ] æ”¶åˆ°response.audio_transcript.done: {client_id}, transcripté•¿åº¦: {len(assistant_text) if assistant_text else 0}")
                
                if assistant_text and realtime_config.VOICE_CALL_INCLUDE_ASSISTANT_TEXT:
                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å‘é€è¿‡ç›¸åŒçš„æ–‡æœ¬ï¼ˆé¿å…é‡å¤æ˜¾ç¤ºï¼Œå› ä¸ºresponse.doneå¯èƒ½ä¹Ÿä¼šåŒ…å«ç›¸åŒæ–‡æœ¬ï¼‰
                    current_time = time.time()
                    if client_id not in self._assistant_text_sent:
                        self._assistant_text_sent[client_id] = {}
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨5ç§’å†…å‘é€è¿‡ç›¸åŒæ–‡æœ¬ï¼ˆåŒä¸€è½®å¯¹è¯çš„AIå›å¤ï¼‰
                    text_key = assistant_text.strip()
                    if text_key in self._assistant_text_sent[client_id]:
                        sent_time = self._assistant_text_sent[client_id][text_key]
                        if current_time - sent_time < 5.0:  # 5ç§’å†…çš„é‡å¤æ–‡æœ¬ä¸å‘é€
                            log.info(f"âš ï¸ [AIè½¬å½•] å·²å‘é€è¿‡ç›¸åŒçš„æ–‡æœ¬ï¼ˆ{current_time - sent_time:.2f}ç§’å‰ï¼‰ï¼Œè·³è¿‡å‘é€: {client_id}")
                            return
                    
                    # è®°å½•å·²å‘é€çš„æ–‡æœ¬å’Œæ—¶é—´æˆ³
                    self._assistant_text_sent[client_id][text_key] = current_time
                    # æ¸…ç†5ç§’å‰çš„è®°å½•ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰
                    for key, ts in list(self._assistant_text_sent[client_id].items()):
                        if current_time - ts > 5.0:
                            del self._assistant_text_sent[client_id][key]
                    
                    display_text = assistant_text[:50] + "..." if len(assistant_text) > 50 else assistant_text
                    log.info(f"ğŸ“ [AIè½¬å½•] å®Œæ•´æ–‡æœ¬: {client_id}, æ–‡æœ¬: {display_text}")
                    # å‘é€AIå›å¤æ–‡æœ¬åˆ°å‰ç«¯
                    await websocket_manager.send_message(client_id, {
                        "type": "transcription_result",
                        "text": assistant_text,  # AIå›å¤æ–‡æœ¬
                        "assistant_text": assistant_text,  # æ˜ç¡®æ ‡è¯†ä¸ºAIå›å¤
                        "timestamp": current_time,
                        "client_id": client_id,
                        "scenario": "voice_call",
                        "message_id": f"voice-call-assistant-{client_id}-{int(current_time * 1000)}",
                        "role": "assistant"  # æ˜ç¡®æ ‡è¯†ä¸ºAIå›å¤
                    })
                    log.info(f"âœ… [AIè½¬å½•] å·²å‘é€å®Œæ•´æ–‡æœ¬åˆ°å‰ç«¯: {client_id}, æ–‡æœ¬é•¿åº¦: {len(assistant_text)}")
            
            elif message_type == "response.done":
                # ğŸ”§ å“åº”å®Œæˆ - ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼ˆå¦‚æœresponse.audio_transcript.doneæ²¡æœ‰åŒ…å«æ–‡æœ¬ï¼‰
                # æ ¹æ®OpenAIæ–‡æ¡£ï¼šresponse.doneåŒ…å«å®Œæ•´çš„å“åº”ä¿¡æ¯ï¼ŒåŒ…æ‹¬AIå›å¤çš„transcript
                # æ³¨æ„ï¼šå¦‚æœresponse.audio_transcript.doneå·²ç»å‘é€äº†æ–‡æœ¬ï¼Œè¿™é‡Œä¼šè¢«è·³è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
                log.info(f"ğŸ” [å“åº”å®Œæˆ] æ”¶åˆ°response.done: {client_id}")
                response_data = data.get("response", {})
                output_items = response_data.get("output", [])
                assistant_text = None
                
                # ä»response.outputä¸­æå–AIå›å¤æ–‡æœ¬ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
                for item in output_items:
                    if item.get("role") == "assistant":
                        content_list = item.get("content", [])
                        for content_item in content_list:
                            if content_item.get("type") == "audio":
                                transcript = content_item.get("transcript", "")
                                if transcript:
                                    assistant_text = transcript
                                    log.info(f"ğŸ” [å“åº”å®Œæˆ] ä»response.outputä¸­æå–åˆ°transcript: {client_id}, æ–‡æœ¬é•¿åº¦: {len(transcript)}, æ–‡æœ¬: {transcript[:100]}")
                                    break
                        if assistant_text:
                            break
                
                if assistant_text and realtime_config.VOICE_CALL_INCLUDE_ASSISTANT_TEXT:
                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å‘é€è¿‡ç›¸åŒçš„æ–‡æœ¬ï¼ˆé¿å…é‡å¤æ˜¾ç¤ºï¼‰
                    current_time = time.time()
                    if client_id not in self._assistant_text_sent:
                        self._assistant_text_sent[client_id] = {}
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨5ç§’å†…å‘é€è¿‡ç›¸åŒæ–‡æœ¬ï¼ˆåŒä¸€è½®å¯¹è¯çš„AIå›å¤ï¼‰
                    text_key = assistant_text.strip()
                    if text_key in self._assistant_text_sent[client_id]:
                        sent_time = self._assistant_text_sent[client_id][text_key]
                        if current_time - sent_time < 5.0:  # 5ç§’å†…çš„é‡å¤æ–‡æœ¬ä¸å‘é€
                            log.info(f"âš ï¸ [å“åº”å®Œæˆ] å·²å‘é€è¿‡ç›¸åŒçš„æ–‡æœ¬ï¼ˆ{current_time - sent_time:.2f}ç§’å‰ï¼‰ï¼Œè·³è¿‡å‘é€: {client_id}")
                            return
                    
                    # è®°å½•å·²å‘é€çš„æ–‡æœ¬å’Œæ—¶é—´æˆ³
                    self._assistant_text_sent[client_id][text_key] = current_time
                    # æ¸…ç†5ç§’å‰çš„è®°å½•ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰
                    for key, ts in list(self._assistant_text_sent[client_id].items()):
                        if current_time - ts > 5.0:
                            del self._assistant_text_sent[client_id][key]
                    
                    display_text = assistant_text[:50] + "..." if len(assistant_text) > 50 else assistant_text
                    log.info(f"ğŸ“ [å“åº”å®Œæˆ] å®Œæ•´æ–‡æœ¬: {client_id}, æ–‡æœ¬: {display_text}")
                    # å‘é€AIå›å¤æ–‡æœ¬åˆ°å‰ç«¯
                    await websocket_manager.send_message(client_id, {
                        "type": "transcription_result",
                        "text": assistant_text,  # AIå›å¤æ–‡æœ¬
                        "assistant_text": assistant_text,  # æ˜ç¡®æ ‡è¯†ä¸ºAIå›å¤
                        "timestamp": current_time,
                        "client_id": client_id,
                        "scenario": "voice_call",
                        "message_id": f"voice-call-assistant-{client_id}-{int(current_time * 1000)}",
                        "role": "assistant"  # æ˜ç¡®æ ‡è¯†ä¸ºAIå›å¤
                    })
                    log.info(f"âœ… [å“åº”å®Œæˆ] å·²å‘é€å®Œæ•´æ–‡æœ¬åˆ°å‰ç«¯: {client_id}, æ–‡æœ¬é•¿åº¦: {len(assistant_text)}")
                else:
                    log.debug(f"[å“åº”å®Œæˆ] æœªæ‰¾åˆ°AIå›å¤æ–‡æœ¬: {client_id}")
                
            elif message_type == "response.created":
                # å“åº”åˆ›å»º
                log.debug(f"å“åº”åˆ›å»º: {client_id}")
                
            elif message_type == "input_audio_buffer.speech_started":
                # æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                log.debug(f"æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹: {client_id}")
                
            elif message_type == "input_audio_buffer.speech_stopped":
                # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
                log.debug(f"æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ: {client_id}")
                
            elif message_type == "session.created":
                # ä¼šè¯å·²åˆ›å»º
                log.info(f"ğŸ“‹ æ”¶åˆ°session.createdäº‹ä»¶: {client_id}")
                
            elif message_type == "session.updated":
                # ä¼šè¯é…ç½®å·²æ›´æ–°
                log.info(f"âœ… ä¼šè¯é…ç½®å·²æ›´æ–°: {client_id}")
                
            elif message_type == "error":
                # å¤„ç†é”™è¯¯
                error_info = data.get("error", {})
                error_message = error_info.get("message", "Unknown error")
                await self._send_error(client_id, f"Realtime APIé”™è¯¯: {error_message}")
            
        except Exception as e:
            log.error(f"å¤„ç†Realtime APIå“åº”å¤±è´¥: {client_id}, é”™è¯¯: {e}")
    
    async def _cleanup_connection(self, client_id: str):
        """
        æ¸…ç†è¿æ¥
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
        """
        try:
            # å…³é—­WebSocketè¿æ¥
            if client_id in self.realtime_connections:
                websocket = self.realtime_connections[client_id]
                await websocket.close()
                del self.realtime_connections[client_id]
            
            # å–æ¶ˆä»»åŠ¡
            if client_id in self.message_tasks:
                task = self.message_tasks[client_id]
                task.cancel()
                del self.message_tasks[client_id]
            
            # æ¸…ç†AIå›å¤æ–‡æœ¬ç›¸å…³æ•°æ®
            if client_id in self._assistant_text_sent:
                del self._assistant_text_sent[client_id]
            
            log.info(f"è¿æ¥å·²æ¸…ç†: {client_id}")
            
        except Exception as e:
            log.error(f"æ¸…ç†è¿æ¥å¤±è´¥: {client_id}, é”™è¯¯: {e}")
    
    async def _send_error(self, client_id: str, error_message: str):
        """
        å‘é€é”™è¯¯æ¶ˆæ¯
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            error_message: é”™è¯¯æ¶ˆæ¯
        """
        try:
            await websocket_manager.send_message(client_id, {
                "type": "error",
                "error": {
                    "message": error_message,
                    "type": "voice_call_error",
                    "code": "processing_failed"
                },
                "timestamp": time.time(),
                "client_id": client_id
            })
        except Exception as e:
            log.error(f"å‘é€é”™è¯¯æ¶ˆæ¯å¤±è´¥: {client_id}, é”™è¯¯: {e}")
    
    def get_active_calls(self) -> Dict[str, Any]:
        """
        è·å–æ´»è·ƒé€šè¯åˆ—è¡¨
        
        Returns:
            Dict: æ´»è·ƒé€šè¯ä¿¡æ¯
        """
        return self.active_calls.copy()
    
    def is_call_active(self, client_id: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒé€šè¯
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: æ˜¯å¦æœ‰æ´»è·ƒé€šè¯
        """
        return client_id in self.active_calls


# åˆ›å»ºå…¨å±€è¯­éŸ³é€šè¯å¤„ç†å™¨å®ä¾‹
voice_call_handler = VoiceCallHandler()
