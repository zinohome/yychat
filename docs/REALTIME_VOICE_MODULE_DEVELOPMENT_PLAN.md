# ç‹¬ç«‹å®æ—¶è¯­éŸ³æ¨¡å—å¼€å‘è®¡åˆ’

**é¡¹ç›®**: YYChat ç‹¬ç«‹å®æ—¶è¯­éŸ³æ¨¡å—å¼€å‘  
**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025å¹´1æœˆ15æ—¥  
**ç›®æ ‡**: åŸºäºOpenAI Agents SDKå®ç°ç‹¬ç«‹å®æ—¶è¯­éŸ³å¯¹è¯åŠŸèƒ½

---

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### å¼€å‘ç›®æ ‡
- âœ… **ä¿æŒç°æœ‰åŠŸèƒ½**ï¼šæ–‡æœ¬å¯¹è¯ã€å½•éŸ³å¯¹è¯åŠŸèƒ½å®Œå…¨ä¸å˜
- âœ… **æ–°å¢å®æ—¶è¯­éŸ³**ï¼šåŸºäºOpenAI Agents SDKçš„ç‹¬ç«‹å®æ—¶è¯­éŸ³æ¨¡å—
- âœ… **é›¶é£é™©è¿ç§»**ï¼šä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼Œå¯éšæ—¶å›é€€
- âœ… **åŠŸèƒ½å¤ç”¨**ï¼šå¤ç”¨ç°æœ‰è®°å¿†ã€äººæ ¼åŒ–ã€å·¥å…·è°ƒç”¨åŠŸèƒ½

### æŠ€æœ¯çº¦æŸ
- **åç«¯æŠ€æœ¯æ ˆ**ï¼šä¿æŒFastAPI + WebSocket + OpenAI API
- **å‰ç«¯æŠ€æœ¯æ ˆ**ï¼šä¿æŒDash + Plotly + Web Audio API
- **ç°æœ‰åŠŸèƒ½**ï¼šå®Œå…¨ä¸å˜ï¼Œé›¶å½±å“
- **æ–°åŠŸèƒ½**ï¼šç‹¬ç«‹æ¨¡å—ï¼Œé€šè¿‡é€‚é…å™¨å¤ç”¨ç°æœ‰ç»„ä»¶

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ç°æœ‰åŠŸèƒ½ (ä¿æŒä¸å˜)"
        A[æ–‡æœ¬å¯¹è¯] --> A1[ChatEngine]
        B[å½•éŸ³å¯¹è¯] --> B1[VoiceRecorder]
        C[è®°å¿†ç³»ç»Ÿ] --> C1[AsyncChatMemory]
        D[äººæ ¼åŒ–] --> D1[PersonalityManager]
        E[å·¥å…·è°ƒç”¨] --> E1[ToolManager]
    end
    
    subgraph "æ–°å¢å®æ—¶è¯­éŸ³æ¨¡å—"
        F[å®æ—¶è¯­éŸ³æ¨¡å—] --> F1[RealtimeVoiceAgent]
        F --> F2[VoiceProcessor]
        F --> F3[AudioStreamHandler]
    end
    
    subgraph "é€‚é…å™¨å±‚"
        G[è®°å¿†é€‚é…å™¨] --> C1
        H[äººæ ¼é€‚é…å™¨] --> D1
        I[å·¥å…·é€‚é…å™¨] --> E1
    end
    
    F --> G
    F --> H
    F --> I
    
    subgraph "å‰ç«¯è·¯ç”±"
        J[æ™ºèƒ½è·¯ç”±] --> A
        J --> B
        J --> F
    end
```

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### 1. ç‹¬ç«‹å®æ—¶è¯­éŸ³æ¨¡å—
```python
# core/realtime_voice_agent.py
class RealtimeVoiceAgent:
    """ç‹¬ç«‹çš„å®æ—¶è¯­éŸ³ä»£ç†"""
    def __init__(self):
        # æ ¸å¿ƒç»„ä»¶
        self.agent = OpenAIRealtimeAgent()
        self.voice_processor = VoiceProcessor()
        self.audio_stream_handler = AudioStreamHandler()
        
        # é€‚é…å™¨ï¼ˆå¤ç”¨ç°æœ‰åŠŸèƒ½ï¼‰
        self.memory_adapter = MemoryAdapter()
        self.personality_adapter = PersonalityAdapter()
        self.tool_adapter = ToolAdapter()
    
    async def process_realtime_voice(self, audio_stream, context):
        """å¤„ç†å®æ—¶è¯­éŸ³æµ"""
        pass
```

#### 2. é€‚é…å™¨å±‚è®¾è®¡
```python
# adapters/memory_adapter.py
class MemoryAdapter:
    """è®°å¿†ç³»ç»Ÿé€‚é…å™¨"""
    def __init__(self, existing_memory_system):
        self.memory = existing_memory_system
    
    async def get_relevant_memory(self, conversation_id, query):
        """å¤ç”¨ç°æœ‰è®°å¿†æ£€ç´¢åŠŸèƒ½"""
        return await self.memory.get_relevant_memory(conversation_id, query)
    
    async def save_memory(self, conversation_id, content):
        """å¤ç”¨ç°æœ‰è®°å¿†ä¿å­˜åŠŸèƒ½"""
        return await self.memory.save_memory(conversation_id, content)
```

---

## ğŸ“… å¼€å‘è®¡åˆ’

### é˜¶æ®µ1ï¼šåŸºç¡€æ¶æ„æ­å»º (ç¬¬1-2å‘¨)

#### 1.1 åç«¯åŸºç¡€æ¶æ„

**ä»»åŠ¡1.1.1ï¼šåˆ›å»ºç‹¬ç«‹å®æ—¶è¯­éŸ³æ¨¡å—**
```python
# æ–‡ä»¶ï¼šcore/realtime_voice_agent.py
class RealtimeVoiceAgent:
    """ç‹¬ç«‹çš„å®æ—¶è¯­éŸ³ä»£ç†"""
    
    def __init__(self):
        # åˆå§‹åŒ–OpenAI Agents SDK
        self.agent = RealtimeAgent()
        self.voice_processor = VoiceProcessor()
        self.audio_stream_handler = AudioStreamHandler()
        
        # åˆå§‹åŒ–é€‚é…å™¨
        self.memory_adapter = None  # å°†åœ¨é˜¶æ®µ2å®ç°
        self.personality_adapter = None  # å°†åœ¨é˜¶æ®µ2å®ç°
        self.tool_adapter = None  # å°†åœ¨é˜¶æ®µ2å®ç°
    
    async def process_realtime_voice(self, audio_stream, context):
        """å¤„ç†å®æ—¶è¯­éŸ³æµ"""
        try:
            # 1. éŸ³é¢‘æµå¤„ç†
            processed_audio = await self.voice_processor.process(audio_stream)
            
            # 2. å‘é€åˆ°OpenAI Agents SDK
            response = await self.agent.process_audio(processed_audio, context)
            
            # 3. å¤„ç†å“åº”
            return await self._handle_response(response, context)
            
        except Exception as e:
            log.error(f"å®æ—¶è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _handle_response(self, response, context):
        """å¤„ç†AIå“åº”"""
        # å®ç°å“åº”å¤„ç†é€»è¾‘
        pass
```

**ä»»åŠ¡1.1.2ï¼šåˆ›å»ºéŸ³é¢‘æµå¤„ç†å™¨**
```python
# æ–‡ä»¶ï¼šcore/realtime_voice_processor.py
class VoiceProcessor:
    """å®æ—¶è¯­éŸ³å¤„ç†å™¨"""
    
    def __init__(self):
        self.audio_context = None
        self.analyser = None
        self.is_processing = False
    
    async def process(self, audio_stream):
        """å¤„ç†éŸ³é¢‘æµ"""
        try:
            # éŸ³é¢‘é¢„å¤„ç†
            processed_audio = await self._preprocess_audio(audio_stream)
            
            # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
            if await self._detect_speech_activity(processed_audio):
                return processed_audio
            
            return None
            
        except Exception as e:
            log.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _preprocess_audio(self, audio_stream):
        """éŸ³é¢‘é¢„å¤„ç†"""
        # å®ç°éŸ³é¢‘é¢„å¤„ç†é€»è¾‘
        pass
    
    async def _detect_speech_activity(self, audio_data):
        """è¯­éŸ³æ´»åŠ¨æ£€æµ‹"""
        # å®ç°è¯­éŸ³æ´»åŠ¨æ£€æµ‹é€»è¾‘
        pass
```

**ä»»åŠ¡1.1.3ï¼šåˆ›å»ºéŸ³é¢‘æµå¤„ç†å™¨**
```python
# æ–‡ä»¶ï¼šcore/audio_stream_handler.py
class AudioStreamHandler:
    """éŸ³é¢‘æµå¤„ç†å™¨"""
    
    def __init__(self):
        self.active_streams = {}
        self.buffer_size = 1024
        self.sample_rate = 16000
    
    async def handle_audio_stream(self, client_id, audio_chunk):
        """å¤„ç†éŸ³é¢‘æµæ•°æ®"""
        try:
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            if client_id not in self.active_streams:
                self.active_streams[client_id] = AudioBuffer()
            
            buffer = self.active_streams[client_id]
            buffer.add_chunk(audio_chunk)
            
            # æ£€æŸ¥æ˜¯å¦å®Œæ•´
            if buffer.is_complete():
                return await self._process_complete_audio(client_id, buffer)
            
            return None
            
        except Exception as e:
            log.error(f"éŸ³é¢‘æµå¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _process_complete_audio(self, client_id, buffer):
        """å¤„ç†å®Œæ•´éŸ³é¢‘"""
        audio_data = buffer.get_audio_data()
        buffer.clear()
        
        return audio_data
```

#### 1.2 å‰ç«¯åŸºç¡€æ¶æ„

**ä»»åŠ¡1.2.1ï¼šåˆ›å»ºå®æ—¶è¯­éŸ³ç»„ä»¶**
```javascript
// æ–‡ä»¶ï¼šassets/js/realtime_voice_manager.js
class RealtimeVoiceManager {
    constructor() {
        this.isActive = false;
        this.audioContext = null;
        this.mediaStream = null;
        this.websocket = null;
        this.agent = null;
    }
    
    async startRealtimeVoice() {
        try {
            // 1. åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
            await this.initializeAudioContext();
            
            // 2. å»ºç«‹WebSocketè¿æ¥
            await this.establishWebSocketConnection();
            
            // 3. å¯åŠ¨å®æ—¶è¯­éŸ³å¤„ç†
            await this.startVoiceProcessing();
            
            this.isActive = true;
            console.log('å®æ—¶è¯­éŸ³å·²å¯åŠ¨');
            
        } catch (error) {
            console.error('å¯åŠ¨å®æ—¶è¯­éŸ³å¤±è´¥:', error);
            throw error;
        }
    }
    
    async stopRealtimeVoice() {
        try {
            // 1. åœæ­¢éŸ³é¢‘å¤„ç†
            await this.stopVoiceProcessing();
            
            // 2. å…³é—­WebSocketè¿æ¥
            await this.closeWebSocketConnection();
            
            // 3. æ¸…ç†èµ„æº
            await this.cleanup();
            
            this.isActive = false;
            console.log('å®æ—¶è¯­éŸ³å·²åœæ­¢');
            
        } catch (error) {
            console.error('åœæ­¢å®æ—¶è¯­éŸ³å¤±è´¥:', error);
            throw error;
        }
    }
    
    async initializeAudioContext() {
        // å®ç°éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–
    }
    
    async establishWebSocketConnection() {
        // å®ç°WebSocketè¿æ¥å»ºç«‹
    }
    
    async startVoiceProcessing() {
        // å®ç°å®æ—¶è¯­éŸ³å¤„ç†
    }
}
```

**ä»»åŠ¡1.2.2ï¼šåˆ›å»ºå®æ—¶è¯­éŸ³UIç»„ä»¶**
```python
# æ–‡ä»¶ï¼šcomponents/realtime_voice_ui.py
def create_realtime_voice_interface():
    """åˆ›å»ºå®æ—¶è¯­éŸ³ç•Œé¢ç»„ä»¶"""
    return html.Div([
        # å®æ—¶è¯­éŸ³æ§åˆ¶é¢æ¿
        html.Div([
            fac.AntdButton(
                id="realtime-voice-start-btn",
                children="å¼€å§‹å®æ—¶å¯¹è¯",
                type="primary",
                style={"margin": "10px"}
            ),
            fac.AntdButton(
                id="realtime-voice-stop-btn", 
                children="åœæ­¢å®æ—¶å¯¹è¯",
                type="default",
                style={"margin": "10px"}
            ),
            fac.AntdButton(
                id="realtime-voice-mute-btn",
                children="é™éŸ³",
                type="default",
                style={"margin": "10px"}
            )
        ], className="realtime-voice-controls"),
        
        # å®æ—¶è¯­éŸ³çŠ¶æ€æŒ‡ç¤ºå™¨
        html.Div([
            fac.AntdBadge(
                id="realtime-voice-status",
                dot=True,
                color="gray",
                children=html.Span("ç­‰å¾…å¼€å§‹å¯¹è¯")
            )
        ], className="realtime-voice-status"),
        
        # å®æ—¶è¯­éŸ³å†å²è®°å½•
        html.Div([
            html.Div(
                id="realtime-voice-history",
                className="realtime-voice-history"
            )
        ], className="realtime-voice-panel")
    ], className="realtime-voice-interface")
```

#### 1.3 è·¯ç”±é›†æˆ

**ä»»åŠ¡1.3.1ï¼šåˆ›å»ºæ™ºèƒ½è·¯ç”±**
```python
# æ–‡ä»¶ï¼šcore/hybrid_router.py
class HybridChatRouter:
    """æ··åˆèŠå¤©è·¯ç”±å™¨"""
    
    def __init__(self):
        # ç°æœ‰åŠŸèƒ½å¤„ç†å™¨
        self.text_handler = existing_text_handler
        self.voice_recording_handler = existing_voice_handler
        
        # æ–°å¢å®æ—¶è¯­éŸ³å¤„ç†å™¨
        self.realtime_voice_handler = RealtimeVoiceAgent()
    
    async def route_request(self, request_type, data, context):
        """è·¯ç”±è¯·æ±‚åˆ°ç›¸åº”çš„å¤„ç†å™¨"""
        try:
            if request_type == "text":
                return await self.text_handler.process(data, context)
            elif request_type == "voice_recording":
                return await self.voice_recording_handler.process(data, context)
            elif request_type == "realtime_voice":
                return await self.realtime_voice_handler.process_realtime_voice(data, context)
            else:
                raise ValueError(f"æœªçŸ¥çš„è¯·æ±‚ç±»å‹: {request_type}")
                
        except Exception as e:
            log.error(f"è·¯ç”±è¯·æ±‚å¤±è´¥: {e}")
            raise
```

**ä»»åŠ¡1.3.2ï¼šæ›´æ–°WebSocketå¤„ç†å™¨**
```python
# æ–‡ä»¶ï¼šcore/websocket_manager.py (ä¿®æ”¹ç°æœ‰æ–‡ä»¶)
class WebSocketManager:
    def __init__(self):
        # ç°æœ‰åŠŸèƒ½
        self.existing_handlers = existing_handlers
        
        # æ–°å¢å®æ—¶è¯­éŸ³å¤„ç†å™¨
        self.realtime_voice_handler = RealtimeVoiceAgent()
        self.hybrid_router = HybridChatRouter()
    
    async def handle_message(self, client_id, message):
        """å¤„ç†WebSocketæ¶ˆæ¯"""
        try:
            message_type = message.get("type")
            
            # ç°æœ‰åŠŸèƒ½ä¿æŒä¸å˜
            if message_type in ["text_message", "audio_input"]:
                return await self.existing_handlers[message_type](client_id, message)
            
            # æ–°å¢å®æ—¶è¯­éŸ³åŠŸèƒ½
            elif message_type == "realtime_voice":
                return await self.realtime_voice_handler.process_realtime_voice(
                    client_id, message
                )
            
            else:
                raise ValueError(f"æœªçŸ¥çš„æ¶ˆæ¯ç±»å‹: {message_type}")
                
        except Exception as e:
            log.error(f"å¤„ç†WebSocketæ¶ˆæ¯å¤±è´¥: {e}")
            raise
```

### é˜¶æ®µ2ï¼šåŠŸèƒ½é›†æˆ (ç¬¬3-4å‘¨)

#### 2.1 è®°å¿†åŠŸèƒ½é›†æˆ

**ä»»åŠ¡2.1.1ï¼šåˆ›å»ºè®°å¿†é€‚é…å™¨**
```python
# æ–‡ä»¶ï¼šadapters/memory_adapter.py
class MemoryAdapter:
    """è®°å¿†ç³»ç»Ÿé€‚é…å™¨"""
    
    def __init__(self, existing_memory_system):
        self.memory = existing_memory_system
        self.cache = {}  # å®æ—¶è¯­éŸ³ä¸“ç”¨ç¼“å­˜
    
    async def get_relevant_memory(self, conversation_id, query):
        """è·å–ç›¸å…³è®°å¿†"""
        try:
            # å¤ç”¨ç°æœ‰è®°å¿†æ£€ç´¢åŠŸèƒ½
            memories = await self.memory.get_relevant_memory(conversation_id, query)
            
            # å®æ—¶è¯­éŸ³ä¸“ç”¨å¤„ç†
            processed_memories = await self._process_memories_for_realtime(memories)
            
            return processed_memories
            
        except Exception as e:
            log.error(f"è·å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    async def save_memory(self, conversation_id, content, metadata=None):
        """ä¿å­˜è®°å¿†"""
        try:
            # å¤ç”¨ç°æœ‰è®°å¿†ä¿å­˜åŠŸèƒ½
            result = await self.memory.save_memory(conversation_id, content, metadata)
            
            # æ›´æ–°å®æ—¶è¯­éŸ³ç¼“å­˜
            await self._update_realtime_cache(conversation_id, content)
            
            return result
            
        except Exception as e:
            log.error(f"ä¿å­˜è®°å¿†å¤±è´¥: {e}")
            return False
    
    async def _process_memories_for_realtime(self, memories):
        """ä¸ºå®æ—¶è¯­éŸ³å¤„ç†è®°å¿†"""
        # å®ç°å®æ—¶è¯­éŸ³ä¸“ç”¨è®°å¿†å¤„ç†é€»è¾‘
        pass
    
    async def _update_realtime_cache(self, conversation_id, content):
        """æ›´æ–°å®æ—¶è¯­éŸ³ç¼“å­˜"""
        # å®ç°å®æ—¶è¯­éŸ³ç¼“å­˜æ›´æ–°é€»è¾‘
        pass
```

**ä»»åŠ¡2.1.2ï¼šé›†æˆåˆ°å®æ—¶è¯­éŸ³æ¨¡å—**
```python
# æ–‡ä»¶ï¼šcore/realtime_voice_agent.py (ä¿®æ”¹)
class RealtimeVoiceAgent:
    def __init__(self):
        # ç°æœ‰ä»£ç ...
        
        # é›†æˆè®°å¿†é€‚é…å™¨
        from adapters.memory_adapter import MemoryAdapter
        from core.chat_memory import get_async_chat_memory
        
        existing_memory = get_async_chat_memory()
        self.memory_adapter = MemoryAdapter(existing_memory)
    
    async def process_realtime_voice(self, audio_stream, context):
        """å¤„ç†å®æ—¶è¯­éŸ³æµ"""
        try:
            # 1. éŸ³é¢‘æµå¤„ç†
            processed_audio = await self.voice_processor.process(audio_stream)
            
            # 2. è·å–ç›¸å…³è®°å¿†
            conversation_id = context.get("conversation_id")
            if conversation_id:
                memories = await self.memory_adapter.get_relevant_memory(
                    conversation_id, processed_audio.text
                )
                context["memories"] = memories
            
            # 3. å‘é€åˆ°OpenAI Agents SDK
            response = await self.agent.process_audio(processed_audio, context)
            
            # 4. ä¿å­˜è®°å¿†
            if conversation_id and response.text:
                await self.memory_adapter.save_memory(
                    conversation_id, response.text, {"type": "realtime_voice"}
                )
            
            return response
            
        except Exception as e:
            log.error(f"å®æ—¶è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            raise
```

#### 2.2 äººæ ¼åŒ–åŠŸèƒ½é›†æˆ

**ä»»åŠ¡2.2.1ï¼šåˆ›å»ºäººæ ¼é€‚é…å™¨**
```python
# æ–‡ä»¶ï¼šadapters/personality_adapter.py
class PersonalityAdapter:
    """äººæ ¼åŒ–ç³»ç»Ÿé€‚é…å™¨"""
    
    def __init__(self, existing_personality_manager):
        self.personality_manager = existing_personality_manager
        self.active_personalities = {}  # å®æ—¶è¯­éŸ³ä¸“ç”¨äººæ ¼ç¼“å­˜
    
    def get_personality_for_realtime(self, personality_id):
        """è·å–å®æ—¶è¯­éŸ³ä¸“ç”¨äººæ ¼"""
        try:
            # å¤ç”¨ç°æœ‰äººæ ¼ç³»ç»Ÿ
            personality = self.personality_manager.get_personality(personality_id)
            
            if not personality:
                return self._get_default_realtime_personality()
            
            # è½¬æ¢ä¸ºå®æ—¶è¯­éŸ³ä¸“ç”¨æ ¼å¼
            realtime_personality = self._convert_to_realtime_format(personality)
            
            return realtime_personality
            
        except Exception as e:
            log.error(f"è·å–äººæ ¼å¤±è´¥: {e}")
            return self._get_default_realtime_personality()
    
    def _convert_to_realtime_format(self, personality):
        """è½¬æ¢ä¸ºäººæ ¼åŒ–æ ¼å¼"""
        return {
            "instructions": personality.system_prompt,
            "voice_settings": personality.voice_settings,
            "behavior_patterns": personality.behavior_patterns,
            "allowed_tools": personality.allowed_tools
        }
    
    def _get_default_realtime_personality(self):
        """è·å–é»˜è®¤å®æ—¶è¯­éŸ³äººæ ¼"""
        return {
            "instructions": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥è¿›è¡Œå®æ—¶è¯­éŸ³å¯¹è¯ã€‚",
            "voice_settings": {"voice": "alloy", "speed": 1.0},
            "behavior_patterns": {"tone": "friendly", "style": "conversational"},
            "allowed_tools": []
        }
```

**ä»»åŠ¡2.2.2ï¼šé›†æˆåˆ°å®æ—¶è¯­éŸ³æ¨¡å—**
```python
# æ–‡ä»¶ï¼šcore/realtime_voice_agent.py (ä¿®æ”¹)
class RealtimeVoiceAgent:
    def __init__(self):
        # ç°æœ‰ä»£ç ...
        
        # é›†æˆäººæ ¼é€‚é…å™¨
        from adapters.personality_adapter import PersonalityAdapter
        from core.personality_manager import PersonalityManager
        
        existing_personality_manager = PersonalityManager()
        self.personality_adapter = PersonalityAdapter(existing_personality_manager)
    
    async def process_realtime_voice(self, audio_stream, context):
        """å¤„ç†å®æ—¶è¯­éŸ³æµ"""
        try:
            # 1. è·å–äººæ ¼è®¾ç½®
            personality_id = context.get("personality_id")
            personality = self.personality_adapter.get_personality_for_realtime(personality_id)
            context["personality"] = personality
            
            # 2. éŸ³é¢‘æµå¤„ç†
            processed_audio = await self.voice_processor.process(audio_stream)
            
            # 3. å‘é€åˆ°OpenAI Agents SDK
            response = await self.agent.process_audio(processed_audio, context)
            
            return response
            
        except Exception as e:
            log.error(f"å®æ—¶è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            raise
```

#### 2.3 å·¥å…·è°ƒç”¨åŠŸèƒ½é›†æˆ

**ä»»åŠ¡2.3.1ï¼šåˆ›å»ºå·¥å…·é€‚é…å™¨**
```python
# æ–‡ä»¶ï¼šadapters/tool_adapter.py
class ToolAdapter:
    """å·¥å…·è°ƒç”¨ç³»ç»Ÿé€‚é…å™¨"""
    
    def __init__(self, existing_tool_manager):
        self.tool_manager = existing_tool_manager
        self.realtime_tools = {}  # å®æ—¶è¯­éŸ³ä¸“ç”¨å·¥å…·
    
    async def get_tools_for_realtime(self, personality_id=None):
        """è·å–å®æ—¶è¯­éŸ³ä¸“ç”¨å·¥å…·"""
        try:
            # å¤ç”¨ç°æœ‰å·¥å…·ç³»ç»Ÿ
            all_tools = await self.tool_manager.get_available_tools()
            
            # æ ¹æ®äººæ ¼è¿‡æ»¤å·¥å…·
            if personality_id:
                personality = self.personality_manager.get_personality(personality_id)
                if personality and personality.allowed_tools:
                    allowed_tool_names = [tool["tool_name"] for tool in personality.allowed_tools]
                    filtered_tools = [tool for tool in all_tools if tool.name in allowed_tool_names]
                else:
                    filtered_tools = all_tools
            else:
                filtered_tools = all_tools
            
            # è½¬æ¢ä¸ºå®æ—¶è¯­éŸ³ä¸“ç”¨æ ¼å¼
            realtime_tools = self._convert_to_realtime_format(filtered_tools)
            
            return realtime_tools
            
        except Exception as e:
            log.error(f"è·å–å·¥å…·å¤±è´¥: {e}")
            return []
    
    def _convert_to_realtime_format(self, tools):
        """è½¬æ¢ä¸ºå®æ—¶è¯­éŸ³ä¸“ç”¨æ ¼å¼"""
        realtime_tools = []
        for tool in tools:
            realtime_tool = {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.parameters,
                "execute": tool.execute
            }
            realtime_tools.append(realtime_tool)
        
        return realtime_tools
    
    async def execute_realtime_tool(self, tool_name, parameters):
        """æ‰§è¡Œå®æ—¶è¯­éŸ³å·¥å…·"""
        try:
            # å¤ç”¨ç°æœ‰å·¥å…·æ‰§è¡ŒåŠŸèƒ½
            result = await self.tool_manager.execute_tool(tool_name, parameters)
            
            return result
            
        except Exception as e:
            log.error(f"æ‰§è¡Œå·¥å…·å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
```

**ä»»åŠ¡2.3.2ï¼šé›†æˆåˆ°å®æ—¶è¯­éŸ³æ¨¡å—**
```python
# æ–‡ä»¶ï¼šcore/realtime_voice_agent.py (ä¿®æ”¹)
class RealtimeVoiceAgent:
    def __init__(self):
        # ç°æœ‰ä»£ç ...
        
        # é›†æˆå·¥å…·é€‚é…å™¨
        from adapters.tool_adapter import ToolAdapter
        from services.tools.manager import ToolManager
        
        existing_tool_manager = ToolManager()
        self.tool_adapter = ToolAdapter(existing_tool_manager)
    
    async def process_realtime_voice(self, audio_stream, context):
        """å¤„ç†å®æ—¶è¯­éŸ³æµ"""
        try:
            # 1. è·å–å¯ç”¨å·¥å…·
            personality_id = context.get("personality_id")
            tools = await self.tool_adapter.get_tools_for_realtime(personality_id)
            context["tools"] = tools
            
            # 2. éŸ³é¢‘æµå¤„ç†
            processed_audio = await self.voice_processor.process(audio_stream)
            
            # 3. å‘é€åˆ°OpenAI Agents SDK
            response = await self.agent.process_audio(processed_audio, context)
            
            # 4. å¤„ç†å·¥å…·è°ƒç”¨
            if response.tool_calls:
                tool_results = await self._execute_tools(response.tool_calls)
                response.tool_results = tool_results
            
            return response
            
        except Exception as e:
            log.error(f"å®æ—¶è¯­éŸ³å¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _execute_tools(self, tool_calls):
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        results = []
        for tool_call in tool_calls:
            result = await self.tool_adapter.execute_realtime_tool(
                tool_call.name, tool_call.parameters
            )
            results.append(result)
        
        return results
```

### é˜¶æ®µ3ï¼šå‰ç«¯é›†æˆ (ç¬¬5-6å‘¨)

#### 3.1 å‰ç«¯ç»„ä»¶é›†æˆ

**ä»»åŠ¡3.1.1ï¼šåˆ›å»ºå®æ—¶è¯­éŸ³UIç»„ä»¶**
```python
# æ–‡ä»¶ï¼šcomponents/realtime_voice_components.py
def create_realtime_voice_interface():
    """åˆ›å»ºå®æ—¶è¯­éŸ³ç•Œé¢"""
    return html.Div([
        # å®æ—¶è¯­éŸ³æ§åˆ¶é¢æ¿
        html.Div([
            fac.AntdButton(
                id="realtime-voice-start-btn",
                children="å¼€å§‹å®æ—¶å¯¹è¯",
                type="primary",
                style={"margin": "10px", "backgroundColor": "#52c41a"}
            ),
            fac.AntdButton(
                id="realtime-voice-stop-btn",
                children="åœæ­¢å®æ—¶å¯¹è¯", 
                type="default",
                style={"margin": "10px"},
                disabled=True
            ),
            fac.AntdButton(
                id="realtime-voice-mute-btn",
                children="é™éŸ³",
                type="default",
                style={"margin": "10px"}
            )
        ], className="realtime-voice-controls"),
        
        # å®æ—¶è¯­éŸ³çŠ¶æ€æŒ‡ç¤ºå™¨
        html.Div([
            fac.AntdBadge(
                id="realtime-voice-status",
                dot=True,
                color="gray",
                children=html.Span("ç­‰å¾…å¼€å§‹å¯¹è¯")
            ),
            html.Span(" å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼", style={"marginLeft": "10px"})
        ], className="realtime-voice-status"),
        
        # å®æ—¶è¯­éŸ³å†å²è®°å½•
        html.Div([
            html.Div(
                id="realtime-voice-history",
                className="realtime-voice-history",
                style={
                    "height": "300px",
                    "overflowY": "auto",
                    "border": "1px solid #d9d9d9",
                    "borderRadius": "6px",
                    "padding": "10px",
                    "backgroundColor": "#fafafa"
                }
            )
        ], className="realtime-voice-panel"),
        
        # å®æ—¶è¯­éŸ³è®¾ç½®
        html.Div([
            html.H4("å®æ—¶è¯­éŸ³è®¾ç½®"),
            html.Div([
                html.Label("è¯­éŸ³ç±»å‹:"),
                dcc.Dropdown(
                    id="realtime-voice-type",
                    options=[
                        {"label": "Alloy", "value": "alloy"},
                        {"label": "Echo", "value": "echo"},
                        {"label": "Fable", "value": "fable"},
                        {"label": "Onyx", "value": "onyx"},
                        {"label": "Nova", "value": "nova"},
                        {"label": "Shimmer", "value": "shimmer"}
                    ],
                    value="alloy"
                )
            ], style={"margin": "10px"}),
            html.Div([
                html.Label("è¯­é€Ÿ:"),
                dcc.Slider(
                    id="realtime-voice-speed",
                    min=0.5,
                    max=2.0,
                    step=0.1,
                    value=1.0,
                    marks={i: str(i) for i in [0.5, 1.0, 1.5, 2.0]}
                )
            ], style={"margin": "10px"})
        ], className="realtime-voice-settings")
    ], className="realtime-voice-interface")
```

**ä»»åŠ¡3.1.2ï¼šåˆ›å»ºå®æ—¶è¯­éŸ³å›è°ƒ**
```python
# æ–‡ä»¶ï¼šcallbacks/realtime_voice_callback.py
@app.callback(
    [
        Output("realtime-voice-start-btn", "disabled"),
        Output("realtime-voice-stop-btn", "disabled"),
        Output("realtime-voice-mute-btn", "disabled"),
        Output("realtime-voice-status", "children"),
        Output("realtime-voice-history", "children")
    ],
    [
        Input("realtime-voice-start-btn", "nClicks"),
        Input("realtime-voice-stop-btn", "nClicks"),
        Input("realtime-voice-mute-btn", "nClicks")
    ],
    [
        State("realtime-voice-status", "children"),
        State("realtime-voice-history", "children")
    ],
    prevent_initial_call=True
)
def handle_realtime_voice_buttons(start_clicks, stop_clicks, mute_clicks, 
                                 current_status, current_history):
    """å¤„ç†å®æ—¶è¯­éŸ³æŒ‰é’®çŠ¶æ€"""
    from dash import ctx
    
    triggered_id = ctx.triggered_id if ctx.triggered else None
    
    if triggered_id == "realtime-voice-start-btn":
        # å¯åŠ¨å®æ—¶è¯­éŸ³å¯¹è¯
        return (
            True,   # start-btn disabled
            False,  # stop-btn enabled
            False,  # mute-btn enabled
            html.Div([
                fac.AntdBadge(
                    dot=True,
                    color="red",
                    children=html.Span("æ­£åœ¨ç›‘å¬")
                ),
                html.Span(" å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼", style={"marginLeft": "10px"})
            ]),
            current_history
        )
    
    elif triggered_id == "realtime-voice-stop-btn":
        # åœæ­¢å®æ—¶è¯­éŸ³å¯¹è¯
        return (
            False,  # start-btn enabled
            True,   # stop-btn disabled
            True,   # mute-btn disabled
            html.Div([
                fac.AntdBadge(
                    dot=True,
                    color="gray",
                    children=html.Span("ç­‰å¾…å¼€å§‹å¯¹è¯")
                ),
                html.Span(" å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼", style={"marginLeft": "10px"})
            ]),
            current_history
        )
    
    elif triggered_id == "realtime-voice-mute-btn":
        # åˆ‡æ¢é™éŸ³çŠ¶æ€
        return no_update
    
    return no_update
```

#### 3.2 JavaScripté›†æˆ

**ä»»åŠ¡3.2.1ï¼šåˆ›å»ºå®æ—¶è¯­éŸ³ç®¡ç†å™¨**
```javascript
// æ–‡ä»¶ï¼šassets/js/realtime_voice_manager.js
class RealtimeVoiceManager {
    constructor() {
        this.isActive = false;
        this.isMuted = false;
        this.audioContext = null;
        this.mediaStream = null;
        this.websocket = null;
        this.agent = null;
        this.history = [];
    }
    
    async startRealtimeVoice() {
        try {
            console.log('å¯åŠ¨å®æ—¶è¯­éŸ³å¯¹è¯...');
            
            // 1. åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
            await this.initializeAudioContext();
            
            // 2. å»ºç«‹WebSocketè¿æ¥
            await this.establishWebSocketConnection();
            
            // 3. å¯åŠ¨å®æ—¶è¯­éŸ³å¤„ç†
            await this.startVoiceProcessing();
            
            this.isActive = true;
            this.updateUI();
            console.log('å®æ—¶è¯­éŸ³å·²å¯åŠ¨');
            
        } catch (error) {
            console.error('å¯åŠ¨å®æ—¶è¯­éŸ³å¤±è´¥:', error);
            this.showError('å¯åŠ¨å®æ—¶è¯­éŸ³å¤±è´¥: ' + error.message);
        }
    }
    
    async stopRealtimeVoice() {
        try {
            console.log('åœæ­¢å®æ—¶è¯­éŸ³å¯¹è¯...');
            
            // 1. åœæ­¢éŸ³é¢‘å¤„ç†
            await this.stopVoiceProcessing();
            
            // 2. å…³é—­WebSocketè¿æ¥
            await this.closeWebSocketConnection();
            
            // 3. æ¸…ç†èµ„æº
            await this.cleanup();
            
            this.isActive = false;
            this.updateUI();
            console.log('å®æ—¶è¯­éŸ³å·²åœæ­¢');
            
        } catch (error) {
            console.error('åœæ­¢å®æ—¶è¯­éŸ³å¤±è´¥:', error);
            this.showError('åœæ­¢å®æ—¶è¯­éŸ³å¤±è´¥: ' + error.message);
        }
    }
    
    async toggleMute() {
        this.isMuted = !this.isMuted;
        this.updateUI();
        console.log('é™éŸ³çŠ¶æ€:', this.isMuted);
    }
    
    async initializeAudioContext() {
        // å®ç°éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        this.analyser = this.audioContext.createAnalyser();
        this.analyser.fftSize = 256;
        this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
    }
    
    async establishWebSocketConnection() {
        // å®ç°WebSocketè¿æ¥å»ºç«‹
        const wsUrl = window.voiceConfig?.WS_URL || 'ws://localhost:9800/ws/chat';
        this.websocket = new WebSocket(wsUrl);
        
        this.websocket.onopen = () => {
            console.log('å®æ—¶è¯­éŸ³WebSocketè¿æ¥å·²å»ºç«‹');
        };
        
        this.websocket.onmessage = (event) => {
            this.handleWebSocketMessage(event);
        };
        
        this.websocket.onerror = (error) => {
            console.error('å®æ—¶è¯­éŸ³WebSocketé”™è¯¯:', error);
        };
        
        this.websocket.onclose = () => {
            console.log('å®æ—¶è¯­éŸ³WebSocketè¿æ¥å·²å…³é—­');
        };
    }
    
    async startVoiceProcessing() {
        // å®ç°å®æ—¶è¯­éŸ³å¤„ç†
        try {
            this.mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });
            
            const source = this.audioContext.createMediaStreamSource(this.mediaStream);
            source.connect(this.analyser);
            
            this.startAudioAnalysis();
            
        } catch (error) {
            console.error('è·å–éº¦å…‹é£æƒé™å¤±è´¥:', error);
            throw error;
        }
    }
    
    startAudioAnalysis() {
        const analyse = () => {
            if (this.isActive) {
                this.analyser.getByteFrequencyData(this.dataArray);
                
                // æ£€æµ‹è¯­éŸ³æ´»åŠ¨
                const average = this.dataArray.reduce((a, b) => a + b) / this.dataArray.length;
                if (average > 10) {
                    this.handleSpeechDetected();
                }
                
                requestAnimationFrame(analyse);
            }
        };
        
        analyse();
    }
    
    handleSpeechDetected() {
        console.log('æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨');
        // å®ç°è¯­éŸ³æ´»åŠ¨å¤„ç†é€»è¾‘
    }
    
    handleWebSocketMessage(event) {
        try {
            const data = JSON.parse(event.data);
            
            switch (data.type) {
                case 'realtime_voice_response':
                    this.handleVoiceResponse(data);
                    break;
                case 'realtime_voice_error':
                    this.handleVoiceError(data);
                    break;
                default:
                    console.log('æ”¶åˆ°å®æ—¶è¯­éŸ³æ¶ˆæ¯:', data);
            }
        } catch (error) {
            console.error('å¤„ç†WebSocketæ¶ˆæ¯å¤±è´¥:', error);
        }
    }
    
    handleVoiceResponse(data) {
        // å¤„ç†è¯­éŸ³å“åº”
        this.addToHistory('assistant', data.text, data.audio_url);
        this.updateUI();
    }
    
    handleVoiceError(data) {
        // å¤„ç†è¯­éŸ³é”™è¯¯
        this.showError(data.message);
    }
    
    addToHistory(role, content, audioUrl = null) {
        const historyItem = {
            role,
            content,
            audioUrl,
            timestamp: new Date().toLocaleTimeString()
        };
        
        this.history.push(historyItem);
        this.updateHistoryDisplay();
    }
    
    updateHistoryDisplay() {
        const historyElement = document.getElementById('realtime-voice-history');
        if (!historyElement) return;
        
        if (this.history.length === 0) {
            historyElement.innerHTML = `
                <div style="text-align: center; color: #999; font-size: 14px; margin-top: 100px;">
                    æš‚æ— å¯¹è¯è®°å½•
                </div>
            `;
            return;
        }
        
        const historyHTML = this.history.map(item => {
            const isUser = item.role === 'user';
            return `
                <div class="conversation-item ${isUser ? 'user-message' : 'ai-message'}" 
                     style="margin-bottom: 15px; padding: 10px; border-radius: 6px; 
                            background-color: ${isUser ? '#e6f7ff' : '#f6ffed'}; 
                            border-left: 3px solid ${isUser ? '#1890ff' : '#52c41a'};">
                    <div style="font-weight: 600; color: #666; font-size: 12px; margin-bottom: 5px;">
                        ${isUser ? 'ç”¨æˆ·' : 'AIåŠ©æ‰‹'} - ${item.timestamp}
                    </div>
                    <div style="font-size: 14px; line-height: 1.5;">
                        ${item.content}
                    </div>
                    ${item.audioUrl ? `
                        <div style="margin-top: 8px;">
                            <audio controls style="width: 100%; height: 30px;">
                                <source src="${item.audioUrl}" type="audio/mpeg">
                            </audio>
                        </div>
                    ` : ''}
                </div>
            `;
        }).join('');
        
        historyElement.innerHTML = historyHTML;
        historyElement.scrollTop = historyElement.scrollHeight;
    }
    
    updateUI() {
        // æ›´æ–°UIçŠ¶æ€
        const startBtn = document.getElementById('realtime-voice-start-btn');
        const stopBtn = document.getElementById('realtime-voice-stop-btn');
        const muteBtn = document.getElementById('realtime-voice-mute-btn');
        const statusElement = document.getElementById('realtime-voice-status');
        
        if (startBtn) {
            startBtn.disabled = this.isActive;
        }
        
        if (stopBtn) {
            stopBtn.disabled = !this.isActive;
        }
        
        if (muteBtn) {
            muteBtn.textContent = this.isMuted ? 'å–æ¶ˆé™éŸ³' : 'é™éŸ³';
        }
        
        if (statusElement) {
            if (this.isActive) {
                statusElement.innerHTML = `
                    <span class="ant-badge ant-badge-status ant-badge-status-red">
                        <span class="ant-badge-status-dot ant-badge-status-dot-red"></span>
                        <span>æ­£åœ¨ç›‘å¬</span>
                    </span>
                    <span style="margin-left: 10px;">å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼</span>
                `;
            } else {
                statusElement.innerHTML = `
                    <span class="ant-badge ant-badge-status ant-badge-status-gray">
                        <span class="ant-badge-status-dot ant-badge-status-dot-gray"></span>
                        <span>ç­‰å¾…å¼€å§‹å¯¹è¯</span>
                    </span>
                    <span style="margin-left: 10px;">å®æ—¶è¯­éŸ³å¯¹è¯æ¨¡å¼</span>
                `;
            }
        }
    }
    
    showError(message) {
        console.error('å®æ—¶è¯­éŸ³é”™è¯¯:', message);
        // æ˜¾ç¤ºé”™è¯¯æç¤º
        alert(`å®æ—¶è¯­éŸ³é”™è¯¯: ${message}`);
    }
    
    async cleanup() {
        // æ¸…ç†èµ„æº
        if (this.mediaStream) {
            this.mediaStream.getTracks().forEach(track => track.stop());
            this.mediaStream = null;
        }
        
        if (this.audioContext) {
            await this.audioContext.close();
            this.audioContext = null;
        }
        
        if (this.websocket) {
            this.websocket.close();
            this.websocket = null;
        }
    }
}

// å…¨å±€å®ä¾‹
window.realtimeVoiceManager = new RealtimeVoiceManager();

// ç»‘å®šäº‹ä»¶
document.addEventListener('DOMContentLoaded', () => {
    const startBtn = document.getElementById('realtime-voice-start-btn');
    const stopBtn = document.getElementById('realtime-voice-stop-btn');
    const muteBtn = document.getElementById('realtime-voice-mute-btn');
    
    if (startBtn) {
        startBtn.addEventListener('click', () => {
            window.realtimeVoiceManager.startRealtimeVoice();
        });
    }
    
    if (stopBtn) {
        stopBtn.addEventListener('click', () => {
            window.realtimeVoiceManager.stopRealtimeVoice();
        });
    }
    
    if (muteBtn) {
        muteBtn.addEventListener('click', () => {
            window.realtimeVoiceManager.toggleMute();
        });
    }
});
```

### é˜¶æ®µ4ï¼šæµ‹è¯•å’Œä¼˜åŒ– (ç¬¬7-8å‘¨)

#### 4.1 åŠŸèƒ½æµ‹è¯•

**ä»»åŠ¡4.1.1ï¼šå•å…ƒæµ‹è¯•**
```python
# æ–‡ä»¶ï¼štest/test_realtime_voice_agent.py
import pytest
import asyncio
from unittest.mock import Mock, patch
from core.realtime_voice_agent import RealtimeVoiceAgent

class TestRealtimeVoiceAgent:
    """å®æ—¶è¯­éŸ³ä»£ç†æµ‹è¯•"""
    
    @pytest.fixture
    def agent(self):
        """åˆ›å»ºæµ‹è¯•ä»£ç†"""
        return RealtimeVoiceAgent()
    
    @pytest.mark.asyncio
    async def test_process_realtime_voice(self, agent):
        """æµ‹è¯•å®æ—¶è¯­éŸ³å¤„ç†"""
        # æ¨¡æ‹ŸéŸ³é¢‘æµ
        audio_stream = Mock()
        context = {"conversation_id": "test_conv"}
        
        # æ¨¡æ‹Ÿå“åº”
        with patch.object(agent.agent, 'process_audio') as mock_process:
            mock_process.return_value = Mock(text="æµ‹è¯•å“åº”")
            
            result = await agent.process_realtime_voice(audio_stream, context)
            
            assert result.text == "æµ‹è¯•å“åº”"
            mock_process.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_memory_integration(self, agent):
        """æµ‹è¯•è®°å¿†é›†æˆ"""
        # æ¨¡æ‹Ÿè®°å¿†æ£€ç´¢
        with patch.object(agent.memory_adapter, 'get_relevant_memory') as mock_memory:
            mock_memory.return_value = ["ç›¸å…³è®°å¿†1", "ç›¸å…³è®°å¿†2"]
            
            context = {"conversation_id": "test_conv"}
            await agent.process_realtime_voice(Mock(), context)
            
            mock_memory.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_personality_integration(self, agent):
        """æµ‹è¯•äººæ ¼åŒ–é›†æˆ"""
        # æ¨¡æ‹Ÿäººæ ¼è·å–
        with patch.object(agent.personality_adapter, 'get_personality_for_realtime') as mock_personality:
            mock_personality.return_value = {"instructions": "æµ‹è¯•äººæ ¼"}
            
            context = {"personality_id": "test_personality"}
            await agent.process_realtime_voice(Mock(), context)
            
            mock_personality.assert_called_once_with("test_personality")
    
    @pytest.mark.asyncio
    async def test_tool_integration(self, agent):
        """æµ‹è¯•å·¥å…·é›†æˆ"""
        # æ¨¡æ‹Ÿå·¥å…·è·å–
        with patch.object(agent.tool_adapter, 'get_tools_for_realtime') as mock_tools:
            mock_tools.return_value = [{"name": "test_tool", "description": "æµ‹è¯•å·¥å…·"}]
            
            context = {"personality_id": "test_personality"}
            await agent.process_realtime_voice(Mock(), context)
            
            mock_tools.assert_called_once_with("test_personality")
```

**ä»»åŠ¡4.1.2ï¼šé›†æˆæµ‹è¯•**
```python
# æ–‡ä»¶ï¼štest/test_realtime_voice_integration.py
import pytest
import asyncio
from unittest.mock import Mock, patch
from core.hybrid_router import HybridChatRouter

class TestRealtimeVoiceIntegration:
    """å®æ—¶è¯­éŸ³é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def router(self):
        """åˆ›å»ºæµ‹è¯•è·¯ç”±å™¨"""
        return HybridChatRouter()
    
    @pytest.mark.asyncio
    async def test_realtime_voice_routing(self, router):
        """æµ‹è¯•å®æ—¶è¯­éŸ³è·¯ç”±"""
        # æ¨¡æ‹Ÿå®æ—¶è¯­éŸ³è¯·æ±‚
        request_type = "realtime_voice"
        data = {"audio_stream": "test_audio"}
        context = {"conversation_id": "test_conv"}
        
        # æ¨¡æ‹Ÿå“åº”
        with patch.object(router.realtime_voice_handler, 'process_realtime_voice') as mock_process:
            mock_process.return_value = Mock(text="æµ‹è¯•å“åº”")
            
            result = await router.route_request(request_type, data, context)
            
            assert result.text == "æµ‹è¯•å“åº”"
            mock_process.assert_called_once_with(data, context)
    
    @pytest.mark.asyncio
    async def test_existing_functionality_preserved(self, router):
        """æµ‹è¯•ç°æœ‰åŠŸèƒ½ä¿æŒ"""
        # æµ‹è¯•æ–‡æœ¬å¤„ç†
        with patch.object(router.text_handler, 'process') as mock_text:
            mock_text.return_value = Mock(text="æ–‡æœ¬å“åº”")
            
            result = await router.route_request("text", {"text": "æµ‹è¯•"}, {})
            
            assert result.text == "æ–‡æœ¬å“åº”"
            mock_text.assert_called_once()
        
        # æµ‹è¯•è¯­éŸ³å½•åˆ¶
        with patch.object(router.voice_recording_handler, 'process') as mock_voice:
            mock_voice.return_value = Mock(text="è¯­éŸ³å“åº”")
            
            result = await router.route_request("voice_recording", {"audio": "test"}, {})
            
            assert result.text == "è¯­éŸ³å“åº”"
            mock_voice.assert_called_once()
```

#### 4.2 æ€§èƒ½æµ‹è¯•

**ä»»åŠ¡4.2.1ï¼šå»¶è¿Ÿæµ‹è¯•**
```python
# æ–‡ä»¶ï¼štest/test_realtime_voice_performance.py
import pytest
import asyncio
import time
from core.realtime_voice_agent import RealtimeVoiceAgent

class TestRealtimeVoicePerformance:
    """å®æ—¶è¯­éŸ³æ€§èƒ½æµ‹è¯•"""
    
    @pytest.fixture
    def agent(self):
        """åˆ›å»ºæµ‹è¯•ä»£ç†"""
        return RealtimeVoiceAgent()
    
    @pytest.mark.asyncio
    async def test_latency_requirements(self, agent):
        """æµ‹è¯•å»¶è¿Ÿè¦æ±‚"""
        # æµ‹è¯•ç›®æ ‡ï¼šå»¶è¿Ÿ < 2ç§’
        start_time = time.time()
        
        # æ¨¡æ‹Ÿå®æ—¶è¯­éŸ³å¤„ç†
        audio_stream = Mock()
        context = {"conversation_id": "test_conv"}
        
        with patch.object(agent.agent, 'process_audio') as mock_process:
            mock_process.return_value = Mock(text="æµ‹è¯•å“åº”")
            
            await agent.process_realtime_voice(audio_stream, context)
            
            end_time = time.time()
            latency = end_time - start_time
            
            # å»¶è¿Ÿåº”è¯¥å°äº2ç§’
            assert latency < 2.0, f"å»¶è¿Ÿ {latency:.2f}s è¶…è¿‡è¦æ±‚"
    
    @pytest.mark.asyncio
    async def test_memory_performance(self, agent):
        """æµ‹è¯•è®°å¿†æ€§èƒ½"""
        # æµ‹è¯•è®°å¿†æ£€ç´¢æ€§èƒ½
        start_time = time.time()
        
        with patch.object(agent.memory_adapter, 'get_relevant_memory') as mock_memory:
            mock_memory.return_value = ["è®°å¿†1", "è®°å¿†2"]
            
            context = {"conversation_id": "test_conv"}
            await agent.process_realtime_voice(Mock(), context)
            
            end_time = time.time()
            memory_latency = end_time - start_time
            
            # è®°å¿†æ£€ç´¢å»¶è¿Ÿåº”è¯¥å°äº0.5ç§’
            assert memory_latency < 0.5, f"è®°å¿†æ£€ç´¢å»¶è¿Ÿ {memory_latency:.2f}s è¶…è¿‡è¦æ±‚"
    
    @pytest.mark.asyncio
    async def test_concurrent_processing(self, agent):
        """æµ‹è¯•å¹¶å‘å¤„ç†"""
        # æµ‹è¯•å¤šä¸ªå¹¶å‘è¯·æ±‚
        async def process_request(request_id):
            audio_stream = Mock()
            context = {"conversation_id": f"conv_{request_id}"}
            
            with patch.object(agent.agent, 'process_audio') as mock_process:
                mock_process.return_value = Mock(text=f"å“åº”_{request_id}")
                
                return await agent.process_realtime_voice(audio_stream, context)
        
        # å¹¶å‘å¤„ç†10ä¸ªè¯·æ±‚
        tasks = [process_request(i) for i in range(10)]
        results = await asyncio.gather(*tasks)
        
        # æ‰€æœ‰è¯·æ±‚éƒ½åº”è¯¥æˆåŠŸ
        assert len(results) == 10
        for i, result in enumerate(results):
            assert result.text == f"å“åº”_{i}"
```

#### 4.3 ç”¨æˆ·ä½“éªŒæµ‹è¯•

**ä»»åŠ¡4.3.1ï¼šå‰ç«¯åŠŸèƒ½æµ‹è¯•**
```javascript
// æ–‡ä»¶ï¼štest/test_realtime_voice_frontend.js
describe('RealtimeVoiceManager', () => {
    let manager;
    
    beforeEach(() => {
        manager = new RealtimeVoiceManager();
    });
    
    test('should start realtime voice', async () => {
        // æ¨¡æ‹ŸéŸ³é¢‘ä¸Šä¸‹æ–‡
        global.AudioContext = jest.fn(() => ({
            createAnalyser: jest.fn(() => ({
                fftSize: 256,
                frequencyBinCount: 128
            })),
            createMediaStreamSource: jest.fn(),
            close: jest.fn()
        }));
        
        // æ¨¡æ‹ŸgetUserMedia
        global.navigator.mediaDevices = {
            getUserMedia: jest.fn(() => Promise.resolve({
                getTracks: () => [{ stop: jest.fn() }]
            }))
        };
        
        // æ¨¡æ‹ŸWebSocket
        global.WebSocket = jest.fn(() => ({
            onopen: null,
            onmessage: null,
            onerror: null,
            onclose: null,
            close: jest.fn()
        }));
        
        await manager.startRealtimeVoice();
        
        expect(manager.isActive).toBe(true);
    });
    
    test('should stop realtime voice', async () => {
        manager.isActive = true;
        
        await manager.stopRealtimeVoice();
        
        expect(manager.isActive).toBe(false);
    });
    
    test('should toggle mute', () => {
        expect(manager.isMuted).toBe(false);
        
        manager.toggleMute();
        
        expect(manager.isMuted).toBe(true);
    });
    
    test('should handle speech detection', () => {
        const mockDataArray = new Uint8Array(128);
        mockDataArray.fill(50); // æ¨¡æ‹Ÿè¯­éŸ³æ´»åŠ¨
        
        manager.dataArray = mockDataArray;
        manager.handleSpeechDetected = jest.fn();
        
        // æ¨¡æ‹Ÿè¯­éŸ³æ´»åŠ¨æ£€æµ‹
        const average = mockDataArray.reduce((a, b) => a + b) / mockDataArray.length;
        if (average > 10) {
            manager.handleSpeechDetected();
        }
        
        expect(manager.handleSpeechDetected).toHaveBeenCalled();
    });
});
```

---

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### å…³é”®æŠ€æœ¯æ ˆ

#### åç«¯æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: FastAPI (ä¿æŒä¸å˜)
- **WebSocket**: ç°æœ‰WebSocketç®¡ç†å™¨ (ä¿æŒä¸å˜)
- **AI SDK**: OpenAI Agents SDK (æ–°å¢)
- **éŸ³é¢‘å¤„ç†**: ç°æœ‰éŸ³é¢‘æœåŠ¡ (ä¿æŒä¸å˜)
- **è®°å¿†ç³»ç»Ÿ**: ç°æœ‰AsyncChatMemory (é€šè¿‡é€‚é…å™¨å¤ç”¨)
- **äººæ ¼åŒ–**: ç°æœ‰PersonalityManager (é€šè¿‡é€‚é…å™¨å¤ç”¨)
- **å·¥å…·è°ƒç”¨**: ç°æœ‰ToolManager (é€šè¿‡é€‚é…å™¨å¤ç”¨)

#### å‰ç«¯æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: Dash + Plotly (ä¿æŒä¸å˜)
- **éŸ³é¢‘å¤„ç†**: Web Audio API (ä¿æŒä¸å˜)
- **å®æ—¶é€šä¿¡**: WebSocket (ä¿æŒä¸å˜)
- **UIç»„ä»¶**: Ant Design (ä¿æŒä¸å˜)
- **çŠ¶æ€ç®¡ç†**: ç°æœ‰çŠ¶æ€ç®¡ç† (ä¿æŒä¸å˜)

### å…³é”®å®ç°è¦ç‚¹

#### 1. é›¶å½±å“åŸåˆ™
```python
# ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å˜
class ExistingFunctionality:
    def __init__(self):
        # ç°æœ‰æ–‡æœ¬å¯¹è¯åŠŸèƒ½
        self.text_chat = existing_text_chat  # å®Œå…¨ä¸å˜
        
        # ç°æœ‰å½•éŸ³å¯¹è¯åŠŸèƒ½  
        self.voice_recording = existing_voice_recording  # å®Œå…¨ä¸å˜
        
        # ç°æœ‰è®°å¿†ç³»ç»Ÿ
        self.memory = existing_memory_system  # å®Œå…¨ä¸å˜
        
        # ç°æœ‰äººæ ¼åŒ–ç³»ç»Ÿ
        self.personality = existing_personality_system  # å®Œå…¨ä¸å˜
        
        # ç°æœ‰å·¥å…·ç³»ç»Ÿ
        self.tools = existing_tool_system  # å®Œå…¨ä¸å˜
```

#### 2. é€‚é…å™¨æ¨¡å¼
```python
# é€šè¿‡é€‚é…å™¨å¤ç”¨ç°æœ‰åŠŸèƒ½
class AdapterPattern:
    def __init__(self):
        # è®°å¿†é€‚é…å™¨
        self.memory_adapter = MemoryAdapter(existing_memory)
        
        # äººæ ¼é€‚é…å™¨
        self.personality_adapter = PersonalityAdapter(existing_personality)
        
        # å·¥å…·é€‚é…å™¨
        self.tool_adapter = ToolAdapter(existing_tools)
    
    def get_memory(self, conversation_id, query):
        # å¤ç”¨ç°æœ‰è®°å¿†ç³»ç»Ÿ
        return self.memory_adapter.get_relevant_memory(conversation_id, query)
    
    def get_personality(self, personality_id):
        # å¤ç”¨ç°æœ‰äººæ ¼ç³»ç»Ÿ
        return self.personality_adapter.get_personality_for_realtime(personality_id)
    
    def get_tools(self, personality_id):
        # å¤ç”¨ç°æœ‰å·¥å…·ç³»ç»Ÿ
        return self.tool_adapter.get_tools_for_realtime(personality_id)
```

#### 3. æ™ºèƒ½è·¯ç”±
```python
# æ™ºèƒ½è·¯ç”±ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
class SmartRouting:
    def route_request(self, request_type, data, context):
        if request_type == "text":
            # ç°æœ‰æ–‡æœ¬å¤„ç†ï¼Œå®Œå…¨ä¸å˜
            return self.existing_text_handler.process(data, context)
        elif request_type == "voice_recording":
            # ç°æœ‰å½•éŸ³å¤„ç†ï¼Œå®Œå…¨ä¸å˜
            return self.existing_voice_handler.process(data, context)
        elif request_type == "realtime_voice":
            # æ–°å¢å®æ—¶è¯­éŸ³å¤„ç†
            return self.new_realtime_handler.process(data, context)
```

---

## ğŸ“Š é£é™©è¯„ä¼°å’Œç¼“è§£

### é£é™©è¯†åˆ«

| é£é™©ç±»å‹ | é£é™©ç­‰çº§ | å½±å“èŒƒå›´ | ç¼“è§£æªæ–½ |
|----------|----------|----------|----------|
| **ç°æœ‰åŠŸèƒ½å½±å“** | ğŸŸ¢ ä½ | æ— å½±å“ | ç‹¬ç«‹æ¨¡å—ï¼Œé›¶å½±å“ |
| **å¼€å‘å¤æ‚åº¦** | ğŸŸ¡ ä¸­ | å¼€å‘å‘¨æœŸ | åˆ†é˜¶æ®µå¼€å‘ï¼Œé€æ­¥éªŒè¯ |
| **æ€§èƒ½å½±å“** | ğŸŸ¢ ä½ | æ–°åŠŸèƒ½ | ç‹¬ç«‹å¤„ç†ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½ |
| **ç”¨æˆ·æ¥å—åº¦** | ğŸŸ¢ ä½ | æ–°åŠŸèƒ½ | å¯é€‰åŠŸèƒ½ï¼Œä¸å½±å“ç°æœ‰ä½“éªŒ |
| **æŠ€æœ¯é£é™©** | ğŸŸ¡ ä¸­ | æ–°åŠŸèƒ½ | åŸºäºæˆç†ŸSDKï¼Œé£é™©å¯æ§ |

### é£é™©ç¼“è§£ç­–ç•¥

#### 1. é›¶å½±å“ç­–ç•¥
```python
# å®Œå…¨ç‹¬ç«‹çš„æ¨¡å—
class ZeroImpactStrategy:
    def __init__(self):
        # ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å˜
        self.existing_functionality = existing_functionality  # å®Œå…¨ä¸å˜
        
        # æ–°å¢åŠŸèƒ½ç‹¬ç«‹
        self.new_realtime_voice = RealtimeVoiceModule()  # å®Œå…¨ç‹¬ç«‹
    
    def process_request(self, request_type, data):
        if request_type in ["text", "voice_recording"]:
            # ç°æœ‰åŠŸèƒ½ï¼Œå®Œå…¨ä¸å˜
            return self.existing_functionality.process(request_type, data)
        elif request_type == "realtime_voice":
            # æ–°åŠŸèƒ½ï¼Œç‹¬ç«‹å¤„ç†
            return self.new_realtime_voice.process(data)
```

#### 2. æ¸è¿›å¼éƒ¨ç½²
```python
# æ¸è¿›å¼éƒ¨ç½²ç­–ç•¥
class GradualDeployment:
    def __init__(self):
        self.deployment_phases = [
            "åŸºç¡€æ¶æ„æ­å»º",
            "åŠŸèƒ½é›†æˆ",
            "å‰ç«¯é›†æˆ", 
            "æµ‹è¯•ä¼˜åŒ–",
            "ç”Ÿäº§éƒ¨ç½²"
        ]
    
    def deploy_phase(self, phase):
        if phase == "åŸºç¡€æ¶æ„æ­å»º":
            # åªéƒ¨ç½²åŸºç¡€æ¶æ„ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
            pass
        elif phase == "åŠŸèƒ½é›†æˆ":
            # é›†æˆåŠŸèƒ½ï¼Œé€šè¿‡é€‚é…å™¨å¤ç”¨ç°æœ‰åŠŸèƒ½
            pass
        elif phase == "å‰ç«¯é›†æˆ":
            # é›†æˆå‰ç«¯ï¼Œæ–°å¢UIç»„ä»¶
            pass
```

#### 3. å›é€€ç­–ç•¥
```python
# éšæ—¶å›é€€ç­–ç•¥
class RollbackStrategy:
    def __init__(self):
        self.can_rollback = True
        self.rollback_steps = [
            "åœæ­¢æ–°åŠŸèƒ½",
            "æ¢å¤åŸæœ‰è·¯ç”±",
            "æ¸…ç†æ–°ç»„ä»¶",
            "éªŒè¯ç°æœ‰åŠŸèƒ½"
        ]
    
    def rollback(self):
        # å¯ä»¥éšæ—¶å›é€€åˆ°å½“å‰ç‰ˆæœ¬
        # 1. åœæ­¢å®æ—¶è¯­éŸ³åŠŸèƒ½
        # 2. æ¢å¤åŸæœ‰è·¯ç”±é€»è¾‘
        # 3. æ¸…ç†æ–°å¢ç»„ä»¶
        # 4. éªŒè¯ç°æœ‰åŠŸèƒ½æ­£å¸¸
        pass
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### åŠŸèƒ½æ•ˆæœ

| åŠŸèƒ½ | å½“å‰çŠ¶æ€ | é¢„æœŸæ•ˆæœ | æå‡å¹…åº¦ |
|------|----------|----------|----------|
| **æ–‡æœ¬å¯¹è¯** | âœ… æ­£å¸¸ | âœ… å®Œå…¨ä¿æŒ | 0% (æ— å½±å“) |
| **å½•éŸ³å¯¹è¯** | âœ… æ­£å¸¸ | âœ… å®Œå…¨ä¿æŒ | 0% (æ— å½±å“) |
| **è®°å¿†åŠŸèƒ½** | âœ… æ­£å¸¸ | âœ… å®Œå…¨ä¿æŒ | 0% (æ— å½±å“) |
| **äººæ ¼åŒ–** | âœ… æ­£å¸¸ | âœ… å®Œå…¨ä¿æŒ | 0% (æ— å½±å“) |
| **å·¥å…·è°ƒç”¨** | âœ… æ­£å¸¸ | âœ… å®Œå…¨ä¿æŒ | 0% (æ— å½±å“) |
| **å®æ—¶è¯­éŸ³** | âŒ æ—  | âœ… æ–°å¢åŠŸèƒ½ | 100% (å…¨æ–°åŠŸèƒ½) |

### æ€§èƒ½æ•ˆæœ

| æ€§èƒ½æŒ‡æ ‡ | å½“å‰çŠ¶æ€ | é¢„æœŸæ•ˆæœ | æå‡å¹…åº¦ |
|----------|----------|----------|----------|
| **æ–‡æœ¬å¯¹è¯å»¶è¿Ÿ** | 2-3ç§’ | 2-3ç§’ | 0% (æ— å½±å“) |
| **å½•éŸ³å¯¹è¯å»¶è¿Ÿ** | 6-7ç§’ | 6-7ç§’ | 0% (æ— å½±å“) |
| **å®æ—¶è¯­éŸ³å»¶è¿Ÿ** | æ—  | 1-2ç§’ | 100% (å…¨æ–°åŠŸèƒ½) |
| **å†…å­˜ä½¿ç”¨** | åŸºå‡† | åŸºå‡†+20% | 20% (æ–°å¢åŠŸèƒ½) |
| **CPUä½¿ç”¨** | åŸºå‡† | åŸºå‡†+15% | 15% (æ–°å¢åŠŸèƒ½) |

### ç”¨æˆ·ä½“éªŒæ•ˆæœ

| ç”¨æˆ·ä½“éªŒ | å½“å‰çŠ¶æ€ | é¢„æœŸæ•ˆæœ | æå‡å¹…åº¦ |
|----------|----------|----------|----------|
| **åŠŸèƒ½å®Œæ•´æ€§** | 100% | 100% | 0% (æ— å½±å“) |
| **å“åº”é€Ÿåº¦** | åŸºå‡† | åŸºå‡† | 0% (æ— å½±å“) |
| **ç¨³å®šæ€§** | åŸºå‡† | åŸºå‡† | 0% (æ— å½±å“) |
| **æ–°åŠŸèƒ½ä½“éªŒ** | æ—  | ä¼˜ç§€ | 100% (å…¨æ–°ä½“éªŒ) |

---

## ğŸ¯ æ€»ç»“

### å¼€å‘ä¼˜åŠ¿

1. **é›¶é£é™©**ï¼šç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å—å½±å“
2. **é«˜æ•ˆç‡**ï¼šå¤ç”¨ç°æœ‰ç»„ä»¶ï¼Œå¼€å‘å‘¨æœŸçŸ­
3. **åŠŸèƒ½å®Œæ•´**ï¼šä¿æŒæ‰€æœ‰ç°æœ‰åŠŸèƒ½ï¼Œæ–°å¢å®æ—¶è¯­éŸ³
4. **æ¸è¿›å¼**ï¼šå¯ä»¥é€æ­¥éªŒè¯å’Œä¼˜åŒ–
5. **å¯å›é€€**ï¼šéšæ—¶å¯ä»¥å›é€€åˆ°å½“å‰ç‰ˆæœ¬

### æŠ€æœ¯ä¼˜åŠ¿

1. **æ¶æ„æ¸…æ™°**ï¼šç‹¬ç«‹æ¨¡å—ï¼ŒèŒè´£æ˜ç¡®
2. **å¤ç”¨ç°æœ‰**ï¼šé€šè¿‡é€‚é…å™¨å¤ç”¨ç°æœ‰åŠŸèƒ½
3. **æŠ€æœ¯å…ˆè¿›**ï¼šåŸºäºOpenAI Agents SDK
4. **æ€§èƒ½ä¼˜è¶Š**ï¼šå»¶è¿Ÿä»6-7ç§’é™ä½åˆ°1-2ç§’
5. **æ‰©å±•æ€§å¼º**ï¼šæ˜“äºåç»­åŠŸèƒ½æ‰©å±•

### å®æ–½å»ºè®®

1. **ç«‹å³å¼€å§‹**ï¼šåŸºäºç°æœ‰æ¶æ„ï¼Œå¿«é€Ÿå¼€å‘
2. **åˆ†é˜¶æ®µå®æ–½**ï¼šæŒ‰è®¡åˆ’é€æ­¥å®Œæˆå„é˜¶æ®µ
3. **æŒç»­æµ‹è¯•**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½è¦å……åˆ†æµ‹è¯•
4. **ç”¨æˆ·åé¦ˆ**ï¼šåŠæ—¶æ”¶é›†ç”¨æˆ·åé¦ˆï¼ŒæŒç»­ä¼˜åŒ–
5. **æ€§èƒ½ç›‘æ§**ï¼šæŒç»­ç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼Œç¡®ä¿ç¨³å®šæ€§

**è¿™ä¸ªå¼€å‘è®¡åˆ’ç¡®ä¿äº†é›¶é£é™©ã€é«˜æ•ˆç‡ã€åŠŸèƒ½å®Œæ•´çš„å®æ—¶è¯­éŸ³åŠŸèƒ½å®ç°ï¼**
